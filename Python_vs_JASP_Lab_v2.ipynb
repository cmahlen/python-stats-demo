{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Why Python? A Hands-On Comparison with JASP\n",
    "\n",
    "You just learned how to run statistical tests in JASP. Now let's do the **exact same tests** in Python and see what we gain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "why-python",
   "metadata": {},
   "source": [
    "## Why bother with code when JASP exists?\n",
    "\n",
    "JASP is excellent for learning statistical concepts and running quick analyses. Python offers additional capabilities that become valuable as your research grows:\n",
    "\n",
    "| | JASP (GUI) | Python (Code) |\n",
    "|---|---|---|\n",
    "| **Reproducibility** | Need to remember which buttons you clicked | Save code, run again anytime; same result guaranteed |\n",
    "| **Automation** | Analyze 50 brain regions? Click 50 times | Write a loop; done in seconds |\n",
    "| **Flexibility** | Limited to built-in options | Create any analysis you can describe |\n",
    "| **Transparency** | Results appear; steps are hidden | You control (and can inspect) each step |\n",
    "| **Sharing** | Colleague needs JASP installed (3 GB) | Share a .py file or notebook, anyone can run it|\n",
    "| **Scale** | Great for one dataset at a time | Process thousands of files overnight |\n",
    "|**Support**|Sparse and slow; limited to forums that nobody uses|Extensive; StackOverflow and LLMs can fix most issues quickly|\n",
    "\n",
    "Admittedly, I don't know that much about JASP, so I'm basing most of the stuff in the left column on my experience with similar programs.\n",
    "\n",
    "**Transferable skills:** Learning Python for statistics opens doors to machine learning, neuroimaging analysis, bioinformatics, finance, web development, and more. The syntax you learn today applies across all these fields. In fact, **Data Science** is becoming an increasingly common job for <a href=\"https://medium.com/@eboniivori151/from-neuroscience-to-data-science-starting-my-journey-6b62fabc31f5\">neuroscience graduates</a>!\n",
    "\n",
    "**Bottom line:** JASP is great for learning concepts and quick checks. Python gives you power and flexibility for real research.\n",
    "\n",
    "Let's prove it. We'll replicate everything you just did in JASP, and then go further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832adb4b-6c54-427a-b542-963b50912cc7",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "1. Gain basic familiarity with Python programming and some of its libraries. Be able to:\n",
    "   - Load Excel (.xlsx) and CSV files using `pandas`\n",
    "   - Inspect dataframes with `.head()`, `.tail()`, and quality checks\n",
    "   - Make simple graphs (histograms, swarm plots, bar plots) using `matplotlib` and `seaborn`\n",
    "   - Run statistical tests (t-test, ANOVA, Tukey HSD, mixed ANOVA)\n",
    "   - Apply the \"peek-then-analyze\" workflow\n",
    "2. Understand the tradeoffs between GUI- and code-based statistics\n",
    "3. Build confidence experimenting with code (changing colors, parameters, etc.)\n",
    "4. Recognize and interpret basic Python errors "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Setup and Loading Data\n",
    "\n",
    "First, let's load the Python libraries we need. Think of libraries as toolboxes. Each one gives us specific capabilities.\n",
    "\n",
    "Don't worry about the cell below, you don't need to know what it's doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we'll use throughout this lab\n",
    "# Each line loads a different \"toolbox\" of functions\n",
    "\n",
    "import pandas as pd              # pandas: for loading and working with data tables\n",
    "import numpy as np               # numpy: for numerical calculations\n",
    "import matplotlib.pyplot as plt  # matplotlib: for creating basic plots\n",
    "import seaborn as sns            # seaborn: for prettier statistical plots\n",
    "import scipy.stats as stats      # scipy.stats: for statistical tests\n",
    "\n",
    "# --- Colab Setup: Download data files from GitHub ---\n",
    "# This cell automatically downloads the data files if running in Google Colab\n",
    "import os\n",
    "if 'google.colab' in str(get_ipython()) or not os.path.exists('class_data_undergrad.xlsx'):\n",
    "    import urllib.request\n",
    "    base_url = 'https://raw.githubusercontent.com/cmahlen/python-stats-demo/main/'\n",
    "    files = ['class_data_undergrad.xlsx', 'ttest_data.xlsx', 'class_data_longitudinal.xlsx', 'spotify.csv']\n",
    "    for f in files:\n",
    "        if not os.path.exists(f):\n",
    "            print(f\"Downloading {f}...\")\n",
    "            urllib.request.urlretrieve(base_url + f, f)\n",
    "    print(\"Data files ready!\")\n",
    "else:\n",
    "    print(\"Using local data files\")\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-context",
   "metadata": {},
   "source": [
    "### The Study\n",
    "\n",
    "A pharmacology experiment examining how dopaminergic drugs affect locomotor activity in rodents.\n",
    "\n",
    "**Dependent Variable**: Number of squares entered in an open-field test (measure of locomotion)\n",
    "\n",
    "**Independent Variables** (8 drug treatment groups):\n",
    "- **Control**: No drug (baseline)\n",
    "- **Amph**: Amphetamine (dopamine releaser — increases locomotion)\n",
    "- **Res only**: Reserpine (depletes dopamine — decreases locomotion)\n",
    "- **Res+Amph**: Can amphetamine overcome reserpine's effects?\n",
    "- **Res+MT**: Reserpine + alpha-methyltyrosine (blocks dopamine synthesis)\n",
    "- **Res+MT+Amph**: Triple combination\n",
    "- **Res+MT+DOPA**: L-DOPA (dopamine precursor) to restore function?\n",
    "- **Res+MT+Amph+DOPA**: Maximum restoration attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-anova-header",
   "metadata": {},
   "source": [
    "### Loading Data: The Peek-Then-Use Pattern\n",
    "\n",
    "**Good habit:** Always look at your data before analyzing it! This helps you catch problems early.\n",
    "\n",
    "We use `pd.read_excel()` to load Excel files. The `pd.` part means \"use the pandas library.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410dc9b2-1922-4d0f-9b93-cffaa5cd7862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines with a # sign in front is a comment. They will not be run\n",
    "# You can use comments to tell others what you are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-anova-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ANOVA dataset from an Excel file\n",
    "# pd.read_excel() reads the file and stores it in a variable called anova_df\n",
    "# \"df\" is short for \"DataFrame\" — pandas' name for a data table\n",
    "\n",
    "anova_df = pd.read_excel('class_data_undergrad.xlsx')\n",
    "print(\"anova_df loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9d3f53-e98f-4e6e-af5c-b07740d1123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .head() shows the first 5 rows — a quick peek at your data\n",
    "# This is your first sanity check: do the columns look right?\n",
    "anova_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082a38c6-c25b-4b99-b194-56dc88474db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also look at the last five rows with .tail()\n",
    "anova_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad8f6f7-abe7-4cbe-88b3-c707284e2167",
   "metadata": {},
   "source": [
    "More quality checks\n",
    "\n",
    "Always do these after loading data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35606cf6-0087-4ee9-9add-420cee5dc672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len() counts how many rows\n",
    "len(anova_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710805b5-9d4f-4099-bd6a-6af38f535a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .columns gives us the column names\n",
    "anova_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c9c0c2-6071-429a-a212-d711088229cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .isna().sum().sum() counts ALL missing values in the entire dataset\n",
    "print(\"Missing values\")\n",
    "anova_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266e0643-1b9c-4100-b3aa-0d8bdf56896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .unique() shows all the different values in a column\n",
    "print(\"Groups in the data:\")\n",
    "\n",
    "anova_df['Group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6269cf6-ef80-4841-a82e-a1634d3145ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .info() shows column names, data types, and non-null counts\n",
    "print(\"\\nData types and structure:\")\n",
    "anova_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-viz-intro",
   "metadata": {},
   "source": [
    "### Visualize Before Analyzing!\n",
    "\n",
    "**Good habit:** Always plot your data before running statistics. Visualizations help you:\n",
    "- Spot outliers or data entry errors\n",
    "- See the pattern before confirming it with numbers\n",
    "- Choose the right statistical test\n",
    "\n",
    "We'll use a **swarm plot** which shows every individual data point. This is better than a box plot because you see the *actual data*, not just a summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7560f84-faba-4e18-8269-4bf2044388e2",
   "metadata": {},
   "source": [
    "You can use virtually infinitely many colors here. For just some, check out \n",
    "\n",
    "https://matplotlib.org/stable/gallery/color/named_colors.html#css-colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a swarm plot showing every data point\n",
    "# sns.swarmplot() is from seaborn — it plots each observation as a dot\n",
    "\n",
    "plt.figure(figsize=(12, 5))  # figsize sets the width and height in inches\n",
    "\n",
    "sns.swarmplot(data=anova_df,           # which dataset to use\n",
    "              x='Group',                # what goes on the x-axis\n",
    "              y='Squares entered',      # what goes on the y-axis\n",
    "              color='steelblue',        # color of the dots (try 'red', 'green', etc.!)\n",
    "              size=6)                   # size of each dot (try 4, 8, 10!)\n",
    "\n",
    "# This section tweaks the the plot that is created above. \n",
    "\n",
    "# Try experimenting with rotation= to see what it does. \n",
    "plt.xticks(rotation=45, ha='right')  # rotate x labels so they don't overlap\n",
    "plt.title('Locomotor Activity by Treatment Group')\n",
    "plt.ylabel('Squares Entered')\n",
    "plt.xlabel('Treatment Group')\n",
    "plt.tight_layout()  # prevents labels from getting cut off\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0ac34e-530c-4628-81b1-aa0ad392e530",
   "metadata": {},
   "source": [
    "<b>What patterns do you notice? Which groups look different from Control?\n",
    "\n",
    "Try changing the color to 'coral' or 'forestgreen' and re-run the cell!\n",
    "\n",
    "You might notice there is a warning telling you to use stripplot.\n",
    "\n",
    "Try it! Replace `swarmplot` with `stripplot`. No other changes needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23p1b8fvevq",
   "metadata": {},
   "source": [
    "### Quick Terminology: Arguments\n",
    "\n",
    "In the code above, you saw things like `x='Group'` and `color='steelblue'` inside the function. These are called **arguments**; they tell the function what to do.\n",
    "\n",
    "```python\n",
    "sns.swarmplot(data=anova_df, x='Group', y='Squares entered', color='steelblue', size=6)\n",
    "#             ↑              ↑          ↑                    ↑               ↑\n",
    "#             argument 1     arg 2      arg 3                arg 4           arg 5\n",
    "```\n",
    "\n",
    "Each argument controls something:\n",
    "- `data=` — which dataset to use\n",
    "- `x=` — what goes on the x-axis\n",
    "- `y=` — what goes on the y-axis\n",
    "- `color=` — the color of the dots\n",
    "- `size=` — how big the dots are\n",
    "\n",
    "**Pro tip:** When you encounter a new function, look up its documentation to see all available arguments. Here's the swarmplot documentation: https://seaborn.pydata.org/generated/seaborn.swarmplot.html\n",
    "\n",
    "You don't need to memorize arguments, just know how to look them up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3c2269-90d0-490a-bda5-9016fd2444df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate descriptive statistics by group\n",
    "# This is what JASP calls \"Descriptives\"\n",
    "\n",
    "# .groupby('Group') splits the data by treatment group\n",
    "# ['Squares entered'] selects just that column\n",
    "# .agg() calculates multiple statistics at once\n",
    "\n",
    "descriptives = anova_df.groupby('Group')['Squares entered'].agg(['count', 'mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75ef924-c3ba-4f88-b7c5-8ba6b0b98276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what's inside our new variable...\n",
    "\n",
    "descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8498f2a7-32e8-4725-a900-2674607e6604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to be clearer\n",
    "descriptives.columns = ['N', 'Mean', 'SD']\n",
    "\n",
    "# Round to 2 decimal places for readability\n",
    "descriptives = descriptives.round(2)\n",
    "\n",
    "# Reorder groups logically (not alphabetically)\n",
    "group_order = ['Control', 'Amph', 'Res only', 'Res+Amph', 'Res+MT', 'Res+MT+Amph', 'Res+MT+DOPA', 'Res+MT+Amph+DOPA']\n",
    "descriptives = descriptives.reindex(group_order)\n",
    "\n",
    "print(\"Descriptive Statistics by Treatment Group\")\n",
    "print(\"=\" * 50)\n",
    "print(descriptives.to_string())\n",
    "print(\"\\nCompare with your JASP output!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ttest-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: T-Tests\n",
    "\n",
    "Now let's load a different dataset for t-tests. This one compares a \"New\" treatment to an \"Old\" treatment.\n",
    "\n",
    "The t-test spreadsheet is stored in a file called `ttest_data.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e97cea-873c-4264-87da-34281f1c84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the t-test data\n",
    "# This file has two columns: 'New' and 'Old'\n",
    "ttest_df = pd.read_excel('FILENAME.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-ttest-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always peek at your data first!\n",
    "print(\"First few rows:\")\n",
    "\n",
    "# how do you see the first few rows of our new dataframe? \n",
    "# Type here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c492336c-f396-44f3-a61e-1703be045b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nNumber of rows: {len(ttest_df)}\")\n",
    "print(f\"Columns: {list(ttest_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-ttest-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the two groups as separate arrays\n",
    "# .dropna() removes any missing values (NaN)\n",
    "# .values converts from pandas Series to numpy array\n",
    "\n",
    "new_data = ttest_df['New'].dropna().values\n",
    "old_data = ttest_df['Old'].dropna().values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b538f7-6abc-4c9c-9ba0-9707b6488c5c",
   "metadata": {},
   "source": [
    "What is in `new_data` and `old_data`? Type them here to find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140f487d-3e73-4352-bf92-f8e7b8fb6dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176b54b6-4349-47e3-b22c-4e7cffae2c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0d1efe-000e-4ce4-af0c-d9a079013ae6",
   "metadata": {},
   "source": [
    "It's very easy to calculate the mean and std of any list in Python. Just do this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca07a55-4775-42d7-b403-c4cb1afde0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.mean(), new_data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cea437-9188-454f-bc7b-06b1dfea9808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now you try for old_data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef30644-69b9-4fdb-9997-197bad30a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's format it nicely (you don't need to know how do this)\n",
    "print(f\"New group: n={len(new_data)}, mean={new_data.mean():.2f}, SD={new_data.std(ddof=1):.2f}\")\n",
    "print(f\"Old group: n={len(old_data)}, mean={old_data.mean():.2f}, SD={old_data.std(ddof=1):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1af75d8-7417-44c7-80b3-dc4de64b894c",
   "metadata": {},
   "source": [
    "The `.2f` just means we are rounding to two decimal points. If we don't do this, we can get very long, ugly numbers which don't add much additional information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-before-ttest",
   "metadata": {},
   "source": [
    "### Visualize Before Testing\n",
    "\n",
    "Before running any statistical test, we should look at the data. Let's create a histogram to see the distribution of each group.\n",
    "\n",
    "Let's first do a quick visualization using `plt.hist()`.\n",
    "\n",
    "`plt.hist()` just needs one argument, which is an array or list of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1cae9c-3019-4b42-b4bc-d284f82b859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One for new_data...\n",
    "plt.hist(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b95f9be-570d-4ee7-904d-c0232f07212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One for old_data\n",
    "plt.hist(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9380fec-2170-413b-9f98-8b484affd4c0",
   "metadata": {},
   "source": [
    "These are **ugly**. We can do better. Let's see if we can make it prettier. For reference, here is the documentation for plt.hist()\n",
    "\n",
    "https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html\n",
    "\n",
    "Note that it has some other arguments we can give it: \n",
    "\n",
    "- bins\n",
    "- label\n",
    "- alpha\n",
    "- color\n",
    "- edgecolor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "histogram-ttest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create overlapping histograms to compare distributions\n",
    "# plt.hist() creates a histogram\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Plot both groups on the same axes\n",
    "# alpha controls transparency (0=invisible, 1=solid) — try different values!\n",
    "# bins controls how many bars — try 5, 10, 15, 20!\n",
    "plt.hist(new_data, bins=8, alpha=0.6, label='New', color='steelblue', edgecolor='black')\n",
    "plt.hist(old_data, bins=8, alpha=0.6, label='Old', color='coral', edgecolor='black')\n",
    "\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Comparing New vs Old Treatment Groups')\n",
    "plt.legend()  # shows which color is which group\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89d780e-a3d5-4e89-8883-4c7291afcc28",
   "metadata": {},
   "source": [
    "Try changing bins=8 to bins=5 or bins=15 and see how the plot changes!\n",
    "\n",
    "Or, try changing alpha=0.6 to alpha=0.3 or alpha=0.9. What does it do? Which looks better? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-1-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Your Turn: Create a Different Visualization\n",
    "\n",
    "We just made a histogram. Now try creating a **swarm plot** comparing the New and Old groups.\n",
    "\n",
    "You'll need to use `sns.swarmplot()` like we did earlier. If you need a refresher on the arguments, check the documentation: https://seaborn.pydata.org/generated/seaborn.swarmplot.html\n",
    "\n",
    "The code below restructures the data for you. Your job is to fill in the `sns.swarmplot()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-1-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, restructure the data into \"long format\" for seaborn\n",
    "# (This code is provided for you. just run it.)\n",
    "ttest_long = pd.DataFrame({\n",
    "    'Group': ['New']*len(new_data) + ['Old']*len(old_data),\n",
    "    'Score': list(new_data) + list(old_data)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40711dd-0954-4d31-b488-e49f7cb9fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you check what is in ttest_long? Do that here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db504f1b-b85e-4d65-951c-665100332474",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,4))\n",
    "\n",
    "# now run swarmplot:\n",
    "# HINT: look back at what the arguments were last time we used swarmplot.\n",
    "\n",
    "sns.swarmplot(\n",
    "    data=...,\n",
    "    x=\"...\",\n",
    "    y=\"...\",\n",
    "    #anything else you want!\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7e7e87-bfb4-4361-925f-7aa19019f2fc",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal answer (try it on your own first! Struggling is part of the process :))</summary>\n",
    "\n",
    "```python\n",
    "sns.swarmplot(data=ttest_long, x='Group', y='Score', color='purple', size=8)\n",
    "plt.title('New vs Old Treatment')\n",
    "plt.show()\n",
    "```\n",
    "Yours doesn't need to be exactly like this, but this will work :) \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-ttest-intro",
   "metadata": {},
   "source": [
    "### Independent Samples T-Test\n",
    "\n",
    "Great! We just made some nice plots. Now let's see if the groups are actually different. \n",
    "\n",
    "**Research Question**: Is there a difference between the New and Old groups?\n",
    "\n",
    "In JASP: T-Tests → Independent Samples T-Test → drag variables → click options...\n",
    "\n",
    "In Python: One line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd588c0c-e0d0-4e28-9a96-2b3b5fbda037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run an independent samples t-test\n",
    "# stats.ttest_ind() compares two independent groups\n",
    "# It returns two values: the t-statistic and the p-value\n",
    "\n",
    "stats.ttest_ind(new_data, old_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22db6f87-7204-419e-8da3-b47ccaf601e5",
   "metadata": {},
   "source": [
    "The above just prints the results out. Let's save them to variables so that we can use them later.\n",
    "\n",
    "Note the order these were printed above: The first variable will get the t-statistic, the second variable will get the p-value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4b9d22-7339-4064-aca6-0e7c06fe4cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat, p_value = stats.ttest_ind(new_data, old_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-ttest",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the results\n",
    "print(\"INDEPENDENT SAMPLES T-TEST\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"New group mean: {new_data.mean():.2f} (n={len(new_data)})\")\n",
    "print(f\"Old group mean: {old_data.mean():.2f} (n={len(old_data)})\")\n",
    "print(f\"\\nt = {t_stat:.3f}\")\n",
    "print(f\"p = {p_value:.4f}\")\n",
    "\n",
    "# Interpret the result\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nSignificant at alpha = 0.05? Yes\")\n",
    "else:\n",
    "    print(\"\\nSignificant at alpha = 0.05? No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i1q2gymyp1f",
   "metadata": {},
   "source": [
    "### Learning from Errors\n",
    "\n",
    "Errors are normal in programming! Let's intentionally cause one so you know what to expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "svbrg1gk9yn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will cause an error — run it to see what happens!\n",
    "anova_df['Squaresss entered'].head()\n",
    "\n",
    "# Uncomment the line above and run this cell.\n",
    "# You'll get a KeyError because 'Squaresss entered' doesn't exist.\n",
    "#\n",
    "# To fix: Check your spelling by running anova_df.columns\n",
    "# What is the correct thing to put in quotes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06a2438-a4df-45b1-a172-fdadf0237f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#anova_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paired-vs-independent",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Independent vs. Paired T-Tests\n",
    "\n",
    "What happens if we run the same data as a **paired** t-test? The results will differ!\n",
    "\n",
    "- **Independent t-test**: Assumes the groups are unrelated (different subjects)\n",
    "- **Paired t-test**: Assumes each observation in one group is matched to one in the other\n",
    "\n",
    "---\n",
    "\n",
    "**Important Warning:** The following is a \"what happens if we use the wrong test\" demonstration. A paired t-test requires **true subject-level pairing** (e.g., the same person measured before and after treatment). We're artificially pairing unrelated observations here to show how results change — **never do this with real data!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paired-ttest-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare independent vs paired t-tests\n",
    "# For paired t-test, we need equal sample sizes, so we use the smaller n\n",
    "\n",
    "n_min = min(len(new_data), len(old_data))\n",
    "\n",
    "# Take only the first n_min values from each group\n",
    "# WARNING: This is artificial pairing — just for demonstration!\n",
    "new_paired = new_data[:n_min]\n",
    "old_paired = old_data[:n_min]\n",
    "\n",
    "# Independent t-test (what we should use for this data)\n",
    "t_ind, p_ind = stats.ttest_ind(new_paired, old_paired)\n",
    "\n",
    "# Paired t-test (ttest_rel = \"related\" samples)\n",
    "t_paired, p_paired = stats.ttest_rel(new_paired, old_paired)\n",
    "\n",
    "print(\"COMPARISON: Independent vs. Paired T-Tests\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Using first {n_min} observations from each group\\n\")\n",
    "print(f\"Independent t-test: t = {t_ind:.3f}, p = {p_ind:.4f}\")\n",
    "print(f\"Paired t-test:      t = {t_paired:.3f}, p = {p_paired:.4f}\")\n",
    "print(\"\\nKey insight: The p-values differ!\")\n",
    "print(\"\\nWhen to use each:\")\n",
    "print(\"  - Independent: Different subjects in each group (e.g., treatment vs control)\")\n",
    "print(\"  - Paired: Same subjects measured twice (e.g., before vs after)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variance-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Checking Assumptions: Equal Variances\n",
    "\n",
    "The standard t-test assumes both groups have similar variances (spread). If they don't, we should use **Welch's t-test** instead.\n",
    "\n",
    "Let's load a second dataset where the variances are very different, then visualize and test for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276848b7-afbb-47d2-b3f7-6bd942e8d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the second sheet from ttest_data.xlsx — this one has unequal variances\n",
    "# sheet_name=1 means the second sheet (Python counts from 0)\n",
    "\n",
    "ttest_df2 = pd.read_excel('ttest_data.xlsx', sheet_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0a47f0-f3ab-44b3-9acf-936e4af25774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peek at the data\n",
    "print(\"Data Set 2 (Unequal Variances):\")\n",
    "# Your code here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variance-demo-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the two groups\n",
    "new_data2 = ttest_df2['New'].dropna().values\n",
    "old_data2 = ttest_df2['Old'].dropna().values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937d8a81-8fc1-4dad-947f-995377ceb478",
   "metadata": {},
   "source": [
    "Now try calculating the mean and standard deviation of `new_data2` and `old_data2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bfe297-c222-403a-9614-42ff5b0d5c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's summarize everything in a nice little list\n",
    "print(f\"\\nNew group: mean={new_data2.mean():.1f}, SD={new_data2.std(ddof=1):.1f}, variance={new_data2.var(ddof=1):.1f}\")\n",
    "print(f\"Old group: mean={old_data2.mean():.1f}, SD={old_data2.std(ddof=1):.1f}, variance={old_data2.var(ddof=1):.1f}\")\n",
    "print(f\"\\nVariance ratio: {new_data2.var(ddof=1) / old_data2.var(ddof=1):.1f}x difference!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28057219-673e-49b2-986d-9446444b17fe",
   "metadata": {},
   "source": [
    "Reading this is one thing, but it's another (better) thing to *see* it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the variance difference — much clearer than numbers!\n",
    "# Notice how the New group is much more spread out\n",
    "\n",
    "# plt.subplots helps us see two figures side-by-side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Left plot: overlapping histograms\n",
    "axes[0].hist(new_data2, bins=8, alpha=0.6, label='New', color='steelblue', edgecolor='black')\n",
    "axes[0].hist(old_data2, bins=8, alpha=0.6, label='Old', color='coral', edgecolor='black')\n",
    "axes[0].set_xlabel('Score')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Histogram: Different Variances')\n",
    "axes[0].legend()\n",
    "\n",
    "# Right plot: swarm plot\n",
    "# First restructure data for seaborn\n",
    "variance_df = pd.DataFrame({\n",
    "    'Group': ['New']*len(new_data2) + ['Old']*len(old_data2),\n",
    "    'Score': list(new_data2) + list(old_data2)\n",
    "})\n",
    "sns.swarmplot(data=variance_df, x='Group', y='Score', ax=axes[1], palette=['steelblue', 'coral'])\n",
    "axes[1].set_title('Swarm Plot: Different Variances')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6425e11a-f7fa-4935-9b48-c7ef9da21d46",
   "metadata": {},
   "source": [
    "See how the New group's dots are much more spread out? That's unequal variance!\n",
    "\n",
    "Don't worry about the red warning for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563a96b1-f7d1-483e-9a9b-682d30d68a54",
   "metadata": {},
   "source": [
    "How do we actually test to see if the variances are equal? \n",
    "\n",
    "We have another test that does this called Levene's test. Let's use it here. \n",
    "\n",
    "It's basically the same as a t-test: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "levene-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levene's test formally checks if variances are equal\n",
    "# If p < 0.05, variances are significantly different — use Welch's t-test\n",
    "# Welch's t-test is a t-test for unequal variances\n",
    "\n",
    "lev_stat, lev_p = stats.levene(new_data2, old_data2)\n",
    "\n",
    "print(\"LEVENE'S TEST FOR EQUALITY OF VARIANCES\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"Test statistic: {lev_stat:.3f}\")\n",
    "print(f\"p-value: {lev_p:.4f}\")\n",
    "\n",
    "if lev_p < 0.05:\n",
    "    print(\"\\nResult: Variances are UNEQUAL (p < 0.05)\")\n",
    "    print(\"Recommendation: Use Welch's t-test\")\n",
    "else:\n",
    "    print(\"\\nResult: Variances are similar (p >= 0.05)\")\n",
    "    print(\"Recommendation: Standard t-test is fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee728cef-b8fa-41bb-91e1-9af5f99a08b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare standard vs Welch's t-test\n",
    "# The only difference in code is equal_var=True vs equal_var=False\n",
    "\n",
    "# Standard t-test (assumes equal variances)\n",
    "t_standard, p_standard = stats.ttest_ind(new_data2, old_data2, equal_var=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e854dc6-0248-40ab-8ea7-c5abf4d2cf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welch's t-test (does NOT assume equal variances)\n",
    "t_welch, p_welch = stats.ttest_ind(new_data2, old_data2, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welch-ttest",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"T-TEST COMPARISON (Data Set 2)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nStandard t-test (equal_var=True):  t = {t_standard:.3f}, p = {p_standard:.4f}\")\n",
    "print(f\"Welch's t-test  (equal_var=False): t = {t_welch:.3f}, p = {p_welch:.4f}\")\n",
    "print(\"\\nWhen variances are unequal, Welch's t-test is more accurate\")\n",
    "print(\"Many statisticians recommend ALWAYS using Welch's t-test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-2-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Your Turn: Run Levene's Test\n",
    "\n",
    "Run Levene's test on our original t-test data (`new_data` and `old_data`) to check if those groups have equal variances.\n",
    "\n",
    "Use `stats.levene()` just like we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-2-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test whether new_data and old_data have equal variances\n",
    "# Use stats.levene()\n",
    "\n",
    "# YOUR CODE HERE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a61c32-3236-47ed-bcfd-b626bf5ac0e6",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "```python\n",
    "lev_stat, lev_p = stats.levene(new_data, old_data)\n",
    "print(f\"Levene's test: F = {lev_stat:.3f}, p = {lev_p:.4f}\")\n",
    "if lev_p < 0.05:\n",
    "    print(\"Variances are unequal — use Welch's t-test\")\n",
    "else:\n",
    "    print(\"Variances are similar — standard t-test is fine\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anova-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: One-Way ANOVA\n",
    "\n",
    "**Question**: Does locomotor activity differ across the 8 drug treatment groups?\n",
    "\n",
    "In JASP: ANOVA → drag Dependent Variable → drag Fixed Factors → check Post Hoc...\n",
    "\n",
    "In Python: First we need to separate our data by group, then run the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prep-anova-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data by treatment group\n",
    "# We'll store each group's data in a dictionary\n",
    "\n",
    "# A dictionary uses curly braces {} and stores key:value pairs\n",
    "# This initializes the dictionary\n",
    "groups = {}\n",
    "\n",
    "# Loop through each group name and extract that group's data\n",
    "for group_name in group_order:\n",
    "    # anova_df[anova_df['Group'] == group_name] filters to just that group\n",
    "    # ['Squares entered'] selects the column we want\n",
    "    # .values converts to a numpy array\n",
    "    groups[group_name] = anova_df[anova_df['Group'] == group_name]['Squares entered'].values\n",
    "\n",
    "# Check that it worked by printing one group\n",
    "print(f\"Control group data: {groups['Control']}\")\n",
    "print(f\"Control group n = {len(groups['Control'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618eb4b-159f-4092-8869-56fd2769ba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows you all the different group names (keys)\n",
    "groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d37e9ce-622a-4d62-85f8-10e5727725fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups[\"GROUPNAME\"] shows you the values they correspond to\n",
    "for group in groups.keys():\n",
    "    print(f\"First few values of {group}: {groups[group][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anova-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running the ANOVA, let's visualize all groups\n",
    "# This swarm plot shows every data point\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Use order= to control the group order on the x-axis\n",
    "sns.swarmplot(data=anova_df, \n",
    "              x='Group', \n",
    "              y='Squares entered',\n",
    "              order=group_order,\n",
    "              color='darkblue',\n",
    "              size=5,\n",
    "              alpha=0.7)  # slight transparency\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Locomotor Activity by Treatment Group')\n",
    "plt.ylabel('Squares Entered')\n",
    "plt.xlabel('Treatment Group')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c05ecc-a149-4db8-9ad1-2238b4b76ac9",
   "metadata": {},
   "source": [
    "<b> Which groups have high locomotion? Which have almost none?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72609b8d-c739-4c49-9be9-bd013257636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the one-way ANOVA\n",
    "# stats.f_oneway() takes multiple groups as arguments\n",
    "# The * unpacks our dictionary values into separate arguments\n",
    "\n",
    "F_stat, p_value = stats.f_oneway(*groups.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oneway-anova",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate degrees of freedom \n",
    "# the ANOVA is already run, this is just for reporting\n",
    "\n",
    "k = len(groups)       # number of groups\n",
    "N = len(anova_df)     # total sample size\n",
    "df_between = k - 1    # degrees of freedom between groups\n",
    "df_within = N - k     # degrees of freedom within groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90245e81-107a-4951-a7d9-cf0ea3953ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format p-value properly (show \"p < .001\" if very small)\n",
    "if p_value < 0.001:\n",
    "    p_str = \"p < .001\"\n",
    "else:\n",
    "    p_str = f\"p = {p_value:.4f}\"\n",
    "\n",
    "print(\"ONE-WAY ANOVA: Locomotor Activity by Treatment Group\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"\\nF({df_between}, {df_within}) = {F_stat:.2f}, {p_str}\")\n",
    "print(\"\\nCompare with JASP: F(7, 102) = 82.00, p < .001\")\n",
    "\n",
    "print(\"\\nGroup means:\")\n",
    "for group_name in group_order:\n",
    "    mean = groups[group_name].mean()\n",
    "    print(f\"  {group_name:20s}: {mean:6.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posthoc-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Post-Hoc Comparisons (Tukey HSD)\n",
    "\n",
    "The ANOVA tells us groups differ, but **which** groups differ from each other?\n",
    "\n",
    "With 8 groups, we have 8×7/2 = **28 pairwise comparisons**.\n",
    "\n",
    "### Why Not Just Run 28 T-Tests?\n",
    "\n",
    "You might think: \"If I want to compare 8 groups, I'll just run all pairwise t-tests!\"\n",
    "\n",
    "**The problem:** With 28 comparisons at alpha = 0.05, you expect ~1-2 false positives by chance alone. This is called the **multiple comparisons problem**.\n",
    "\n",
    "**Solutions:**\n",
    "1. **Tukey HSD** (what we'll use) — adjusts p-values to control family-wise error rate\n",
    "2. **Bonferroni correction** — multiply each p-value by the number of tests (more conservative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tukey-hsd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tukey_hsd from scipy.stats\n",
    "from scipy.stats import tukey_hsd\n",
    "\n",
    "# Run Tukey HSD on all groups\n",
    "# We pass each group's data as a separate argument\n",
    "result = tukey_hsd(*[groups[g] for g in group_order])\n",
    "\n",
    "print(\"TUKEY HSD POST-HOC COMPARISONS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Comparison':<45} {'Mean Diff':>10} {'p-value':>10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Count significant comparisons\n",
    "n_significant = 0\n",
    "\n",
    "# Loop through all pairs of groups\n",
    "for i in range(len(group_order)):\n",
    "    for j in range(i+1, len(group_order)):\n",
    "        g1, g2 = group_order[i], group_order[j]\n",
    "        \n",
    "        # Calculate mean difference\n",
    "        mean_diff = groups[g1].mean() - groups[g2].mean()\n",
    "        \n",
    "        # Get p-value from the result matrix\n",
    "        p_val = result.pvalue[i, j]\n",
    "        \n",
    "        # Add significance stars\n",
    "        if p_val < 0.001:\n",
    "            sig_marker = \"***\"\n",
    "            n_significant += 1\n",
    "        elif p_val < 0.01:\n",
    "            sig_marker = \"**\"\n",
    "            n_significant += 1\n",
    "        elif p_val < 0.05:\n",
    "            sig_marker = \"*\"\n",
    "            n_significant += 1\n",
    "        else:\n",
    "            sig_marker = \"\"\n",
    "        \n",
    "        comparison = f\"{g1} vs {g2}\"\n",
    "        print(f\"{comparison:<45} {mean_diff:>10.2f} {p_val:>10.3f} {sig_marker}\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"Significant comparisons: {n_significant} of 28\")\n",
    "print(\"\\n*** p < .001, ** p < .01, * p < .05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-3-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Your Turn: Run a T-Test Between Two Groups\n",
    "\n",
    "Run an independent samples t-test comparing the `Control` group to the `Amph` group.\n",
    "\n",
    "Use `stats.ttest_ind()` with the data from the `groups` dictionary.\n",
    "\n",
    "Hint: Access Control data with `groups['Control']` and Amph data with `groups['Amph']`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-3-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Control to Amph using stats.ttest_ind()\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4f5173-dc51-48c3-9c9d-1850d1c6a331",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "```python\n",
    "t_stat, p_val = stats.ttest_ind(groups['Control'], groups['Amph'])\n",
    "print(f\"t = {t_stat:.3f}, p = {p_val:.4f}\")\n",
    "print(f\"Control mean: {groups['Control'].mean():.2f}\")\n",
    "print(f\"Amph mean: {groups['Amph'].mean():.2f}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e598b-86ef-4cdf-a1e7-f8c112e3ddf0",
   "metadata": {},
   "source": [
    "Did you make sure the variances were equal? How would you do this? \n",
    "\n",
    "What other comparisons would you like to see? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0282a10-79f1-4d5e-9644-702e60c59b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mfqp4br804a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Two-Way Repeated Measures ANOVA\n",
    "\n",
    "So far we've analyzed data measured at a single time point. But what if we measure the same subjects at multiple times?\n",
    "\n",
    "**The longitudinal study:** The same animals were tested again 1 week after the initial drug treatment (after the drugs wore off).\n",
    "\n",
    "**Research question:**\n",
    "- Does locomotor activity change over time?\n",
    "- Does the change depend on which drug group the animal was in?\n",
    "- Is there a Drug × Time interaction?\n",
    "\n",
    "This requires a **mixed ANOVA**:\n",
    "- **Between-subjects factor:** Drug treatment (different animals in each group)\n",
    "- **Within-subjects factor:** Time (same animals measured twice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ky37qhnaevr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeated measures ANOVA requires the pingouin library\n",
    "# This cell installs it (only needed once per session in Colab)\n",
    "!pip install pingouin -q\n",
    "import pingouin as pg\n",
    "print(\"pingouin installed!\")\n",
    "print(\"Documentation: https://pingouin-stats.org/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3be3c3-a587-41b7-9516-62642d773c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the longitudinal data\n",
    "# This is stored at class_data_longitudinal.xlsx\n",
    "\n",
    "long_df = pd.read_excel('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5cbf26-b6ec-4e19-8a90-736935897960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now inspect the data\n",
    "print(\"Longitudinal Data (same animals, two time points):\")\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0a499e-adc0-4f5c-857b-77d4ec112ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other things you can do\n",
    "long_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f818e6c7-2ba0-4c4b-8e65-f1c576805674",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655a1f98-a25c-4645-aee0-4e45164b2194",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forwqyabldv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean: Remove rows with missing data (marked as '.')\n",
    "# Convert 1-week column to numeric\n",
    "long_df['Week1'] = pd.to_numeric(long_df['Squares entered 1 week'], errors='coerce')\n",
    "long_df_clean = long_df.dropna(subset=['Week1'])\n",
    "print(f\"Removed {len(long_df) - len(long_df_clean)} rows with missing data\")\n",
    "\n",
    "# Add subject ID (needed for repeated measures)\n",
    "long_df_clean = long_df_clean.reset_index(drop=True)\n",
    "long_df_clean['Subject'] = range(len(long_df_clean))\n",
    "\n",
    "# Reshape to \"long format\" for pingouin\n",
    "# Each row = one observation (subject × time combination)\n",
    "df_time1 = long_df_clean[['Subject', 'Group', 'Squares entered']].copy()\n",
    "df_time1['Time'] = 'Initial'\n",
    "df_time1 = df_time1.rename(columns={'Squares entered': 'Squares'})\n",
    "\n",
    "df_time2 = long_df_clean[['Subject', 'Group', 'Week1']].copy()\n",
    "df_time2['Time'] = 'One Week'\n",
    "df_time2 = df_time2.rename(columns={'Week1': 'Squares'})\n",
    "\n",
    "rm_df = pd.concat([df_time1, df_time2], ignore_index=True)\n",
    "print(\"\\nReshaped data (long format):\")\n",
    "print(rm_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4rgym9k4qzr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize: Does the pattern differ by group over time?\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Calculate means for each Group × Time combination\n",
    "means = rm_df.groupby(['Group', 'Time'])['Squares'].mean().unstack()\n",
    "means = means.reindex(group_order)  # Use our standard group order\n",
    "\n",
    "# Plot\n",
    "means.plot(kind='bar', ax=plt.gca(), color=['steelblue', 'coral'], edgecolor='black')\n",
    "plt.title('Locomotor Activity: Initial vs 1 Week Later')\n",
    "plt.ylabel('Squares Entered (mean)')\n",
    "plt.xlabel('Treatment Group')\n",
    "plt.legend(title='Time')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2de91d-5070-4665-a695-dd7a82745ca3",
   "metadata": {},
   "source": [
    "Notice how Amph drops dramatically. Looks like the drug effect wore off!\n",
    "\n",
    "And the Res groups recovered somewhat over the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cra0w5prydp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the mixed ANOVA using pingouin\n",
    "# - dv: dependent variable (what we're measuring)\n",
    "# - within: within-subjects factor (Time)\n",
    "# - between: between-subjects factor (Group)\n",
    "# - subject: identifies each subject\n",
    "\n",
    "aov = pg.mixed_anova(data=rm_df,\n",
    "                     dv='Squares',\n",
    "                     within='Time',\n",
    "                     between='Group',\n",
    "                     subject='Subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d854aed-3e8f-4e64-bad7-b1fda6f60b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run aov and see what it gives us...\n",
    "aov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71530a7-62ed-4ba2-872e-77c4e1b6a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's grab some of that stuff and reformat it \n",
    "print(\"TWO-WAY MIXED ANOVA RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(aov.round(4).to_string())\n",
    "\n",
    "print(\"\\n--- Interpretation ---\")\n",
    "for idx, row in aov.iterrows():\n",
    "    effect = row['Source']\n",
    "    f_val = row['F']\n",
    "    p_val = row['p-unc']\n",
    "    p_str = \"p < .001\" if p_val < 0.001 else f\"p = {p_val:.4f}\"\n",
    "    sig = \"**SIGNIFICANT**\" if p_val < 0.05 else \"not significant\"\n",
    "    print(f\"{effect}: F = {f_val:.2f}, {p_str} — {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9xk7eqvyipj",
   "metadata": {},
   "source": [
    "### What do the results mean?\n",
    "\n",
    "- **Group effect:** Do drug groups differ overall (averaging across time)?\n",
    "- **Time effect:** Does locomotion change from initial to 1 week (averaging across groups)?\n",
    "- **Group × Time interaction:** Does the TIME effect depend on which GROUP you're in?\n",
    "\n",
    "The **interaction** is often the most interesting! It tells us whether drug effects persist or fade over time differently for different treatments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yvjy684avhj",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Your Turn: Explore the Interaction\n",
    "\n",
    "Try answering these questions using the `rm_df` data and the mixed ANOVA results:\n",
    "\n",
    "1. Which group showed the biggest change from Initial to 1 Week?\n",
    "2. Run the code below to see all the group means — does this match the plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07rh754vzdm3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate means for each Group x Time combination\n",
    "# groupby() splits the data, then we calculate the mean of 'Squares' for each split\n",
    "\n",
    "rm_df.groupby(['Group', 'Time'])['Squares'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opsqe12j2r",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to check your answer</summary>\n",
    "\n",
    "The **Amph** group shows the biggest change (drops from ~92 to ~41 as the drug wore off).\n",
    "\n",
    "The means should match what you see in the bar plot above!\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advantage-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Things Python Can Do That JASP Can't\n",
    "\n",
    "### Advantage 1: Automation\n",
    "\n",
    "What if you needed to run pairwise comparisons for multiple outcome measures? In JASP, you'd click through menus dozens of times. In Python, it's a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automation-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all 28 pairwise t-tests in a loop\n",
    "# This demonstrates automation — NOT recommended without correction!\n",
    "\n",
    "print(\"AUTOMATED PAIRWISE T-TESTS (28 comparisons)\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Store results in a list\n",
    "results_list = []\n",
    "\n",
    "# Nested loops go through all pairs\n",
    "for i in range(len(group_order)):\n",
    "    for j in range(i+1, len(group_order)):  # j > i avoids duplicates\n",
    "        g1, g2 = group_order[i], group_order[j]\n",
    "        \n",
    "        # Run t-test\n",
    "        t, p = stats.ttest_ind(groups[g1], groups[g2])\n",
    "        \n",
    "        # Store in our results list\n",
    "        results_list.append({\n",
    "            'Group 1': g1,\n",
    "            'Group 2': g2,\n",
    "            't': t,\n",
    "            'p': p,\n",
    "            'significant': p < 0.05\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame for easy viewing\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "print(f\"\\nRan {len(results_df)} t-tests in a loop.\")\n",
    "print(f\"Significant results (uncorrected): {results_df['significant'].sum()}\")\n",
    "\n",
    "# Apply Bonferroni correction\n",
    "# Multiply each p-value by the number of tests\n",
    "results_df['p_bonferroni'] = (results_df['p'] * len(results_df)).clip(upper=1.0)\n",
    "results_df['sig_corrected'] = results_df['p_bonferroni'] < 0.05\n",
    "\n",
    "print(f\"Significant after Bonferroni correction: {results_df['sig_corrected'].sum()}\")\n",
    "\n",
    "print(\"\\nIn JASP, you'd click through 28 separate comparisons.\")\n",
    "print(\"In Python, 10 lines of code.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "### Advantage 2: Custom Visualizations\n",
    "\n",
    "JASP gives you canned plots. Python gives you full control over every aspect of your figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bar-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a publication-quality bar plot with error bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Calculate means and standard errors for each group\n",
    "means = [groups[g].mean() for g in group_order]\n",
    "sems = [groups[g].std() / np.sqrt(len(groups[g])) for g in group_order]\n",
    "\n",
    "# Color code by drug effect\n",
    "# Try changing these colors! Options: 'red', 'blue', 'green', 'orange', 'purple', etc.\n",
    "colors = ['green',      # Control\n",
    "          'red',        # Amph (stimulant effect)\n",
    "          'royalblue',  # Res only (depleted)\n",
    "          'orange',     # Res+Amph (partial restoration)\n",
    "          'royalblue',  # Res+MT\n",
    "          'royalblue',  # Res+MT+Amph\n",
    "          'royalblue',  # Res+MT+DOPA\n",
    "          'orange']     # Res+MT+Amph+DOPA (restoration)\n",
    "\n",
    "# Create the bar plot\n",
    "# yerr adds error bars, capsize sets the width of the error bar caps\n",
    "bars = ax.bar(range(len(group_order)), means, yerr=sems, \n",
    "              color=colors, edgecolor='black', capsize=4, alpha=0.8)\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xticks(range(len(group_order)))\n",
    "ax.set_xticklabels(group_order, rotation=45, ha='right', fontsize=10)\n",
    "ax.set_ylabel('Squares Entered (mean +/- SEM)', fontsize=12)\n",
    "ax.set_xlabel('Treatment Group', fontsize=12)\n",
    "\n",
    "# Add title with our computed statistics\n",
    "if p_value < 0.001:\n",
    "    title_p = \"p < .001\"\n",
    "else:\n",
    "    title_p = f\"p = {p_value:.3f}\"\n",
    "ax.set_title(f'Locomotor Activity by Treatment\\nF({df_between}, {df_within}) = {F_stat:.2f}, {title_p}', fontsize=14)\n",
    "\n",
    "# Add a horizontal reference line at Control mean\n",
    "ax.axhline(y=groups['Control'].mean(), color='gray', linestyle='--', alpha=0.5, label='Control baseline')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Color key: Green=Control, Red=Stimulant, Blue=Depleted, Orange=Restored\")\n",
    "print(\"\\nTry changing the colors list above and re-running!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bootstrap-header",
   "metadata": {},
   "source": [
    "### Advantage 3: Bootstrap Confidence Intervals\n",
    "\n",
    "This isn't even an option in JASP's menus. In Python, it's straightforward.\n",
    "\n",
    "### Why Bootstrap?\n",
    "\n",
    "Traditional statistics assume your data follows a specific distribution (usually normal). But what if it doesn't? Or what if you have a small sample?\n",
    "\n",
    "**Bootstrapping** lets you estimate uncertainty without those assumptions:\n",
    "1. Resample your data (with replacement) thousands of times\n",
    "2. Calculate your statistic each time\n",
    "3. The spread of those results IS your confidence interval\n",
    "\n",
    "This is especially useful when:\n",
    "- Sample sizes are small\n",
    "- Data is skewed or has outliers\n",
    "- You want to verify your results aren't dependent on distributional assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bootstrap-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap confidence interval for Amph vs Control difference\n",
    "\n",
    "amph = groups['Amph']\n",
    "control = groups['Control']\n",
    "\n",
    "# Number of bootstrap samples — more = more precise but slower\n",
    "n_bootstrap = 10000\n",
    "\n",
    "# Store bootstrapped differences\n",
    "boot_diffs = []\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Bootstrap loop\n",
    "for _ in range(n_bootstrap):\n",
    "    # Resample WITH replacement (some values will be picked multiple times)\n",
    "    boot_amph = np.random.choice(amph, size=len(amph), replace=True)\n",
    "    boot_ctrl = np.random.choice(control, size=len(control), replace=True)\n",
    "    \n",
    "    # Calculate mean difference for this resample\n",
    "    boot_diffs.append(boot_amph.mean() - boot_ctrl.mean())\n",
    "\n",
    "boot_diffs = np.array(boot_diffs)\n",
    "\n",
    "# Calculate confidence interval using percentiles\n",
    "ci_lower = np.percentile(boot_diffs, 2.5)\n",
    "ci_upper = np.percentile(boot_diffs, 97.5)\n",
    "\n",
    "print(\"BOOTSTRAP ANALYSIS (10,000 resamples)\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"\\nAmphetamine vs Control difference:\")\n",
    "print(f\"  Observed difference: {amph.mean() - control.mean():.1f} squares\")\n",
    "print(f\"  Bootstrap mean:      {np.mean(boot_diffs):.1f} squares\")\n",
    "print(f\"  95% CI: [{ci_lower:.1f}, {ci_upper:.1f}]\")\n",
    "print(f\"\\nProportion where Amph > Control: {(boot_diffs > 0).mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bootstrap-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the bootstrap distribution\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Histogram of bootstrap differences\n",
    "plt.hist(boot_diffs, bins=50, edgecolor='black', alpha=0.7, color='indianred')\n",
    "\n",
    "# Add vertical lines for reference\n",
    "plt.axvline(0, color='black', linewidth=2, linestyle='--', label='No difference')\n",
    "plt.axvline(ci_lower, color='navy', linewidth=2, linestyle=':', label='95% CI')\n",
    "plt.axvline(ci_upper, color='navy', linewidth=2, linestyle=':')\n",
    "\n",
    "plt.xlabel('Amphetamine - Control (squares entered)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Bootstrap Distribution of Mean Difference')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The entire distribution is above zero — strong evidence that Amph > Control!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reproducibility-header",
   "metadata": {},
   "source": [
    "### Advantage 4: Reproducibility\n",
    "\n",
    "If someone asks *\"How did you get that result?\"*, you can hand them this notebook. Every step is documented, every analysis is re-runnable.\n",
    "\n",
    "In JASP, you'd have to write out: *\"I clicked ANOVA, then dragged Squares entered into the dependent variable box, then I dragged Group into the grouping variable, then I checked the Tukey option under Post Hoc...\"*\n",
    "\n",
    "In Python, the code **is** the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9ffc73-a453-40a1-a20a-f673594379f5",
   "metadata": {},
   "source": [
    "### Other advantages\n",
    "\n",
    "1. **Flexibility**: In general, when you use JASP or other software you are limited by what the JASP programmers decide to add. With Python (or R), you can code anything you want.\n",
    "2. **Complexity**: Some GUI-based software tries to make up for deficits in flexibility by programming in a bunch of new add-ons. But these often just make the interface cluttered and more difficult to use. It defeats one of the original purposes of the GUI: it should be simple! With code, you can control exactly how much complexity you want. \n",
    "3. **Packages**: Reserachers almost always use Python and R to make packages for doing more sophisticated analyses, like those in neuroimaging or genetics. These are rarely in JASP or other GUI-based software.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "error-box",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Errors and What They Mean\n",
    "\n",
    "When you see an error, don't panic! Here's what common errors mean:\n",
    "\n",
    "| Error | What it means | How to fix |\n",
    "|-------|---------------|------------|\n",
    "| `FileNotFoundError` | Python can't find the file | Check filename spelling, make sure file is in the same folder as the notebook |\n",
    "| `KeyError: 'column_name'` | That column doesn't exist in your data | Check spelling with `df.columns` to see all column names |\n",
    "| `ValueError: could not convert string to float` | There's text in a column that should be numbers | Check for header rows or non-numeric data with `df.head()` |\n",
    "| `NameError: name 'x' is not defined` | You're using a variable before creating it | Make sure you ran the cell that creates that variable first |\n",
    "| `IndentationError` | Python code isn't lined up correctly | Check that spaces/tabs are consistent |\n",
    "\n",
    "**Pro tip:** Read error messages from the bottom up — the last line usually tells you what went wrong!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rm-anova-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonus: More Repeated Measures Options\n",
    "\n",
    "In Part 5, we used `pingouin` for the mixed ANOVA. The library also supports:\n",
    "\n",
    "**Within-subjects only ANOVA** (all factors are repeated measures):\n",
    "```python\n",
    "pg.rm_anova(data=df, dv='Score', within='Time', subject='Subject')\n",
    "```\n",
    "\n",
    "**Multiple within-subjects factors**:\n",
    "```python\n",
    "pg.rm_anova(data=df, dv='Score', within=['Time', 'Condition'], subject='Subject')\n",
    "```\n",
    "\n",
    "See the full documentation at: [pingouin-stats.org](https://pingouin-stats.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recap",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checkpoint: JASP vs Python\n",
    "\n",
    "You just replicated **every test** from the JASP lab in Python (hopefully). Let's count the lines of code:\n",
    "\n",
    "| Test | Python Code | JASP |\n",
    "|------|-------------|------|\n",
    "| Independent t-test | `stats.ttest_ind(a, b)` — **1 line** | 4-5 clicks, drag variables |\n",
    "| Paired t-test | `stats.ttest_rel(a, b)` — **1 line** | Reshape data, 4-5 clicks |\n",
    "| Welch's t-test | `stats.ttest_ind(a, b, equal_var=False)` — **1 line** | Buried in options menu |\n",
    "| Levene's test | `stats.levene(a, b)` — **1 line** | Separate analysis |\n",
    "| One-way ANOVA | `stats.f_oneway(g1, g2, ...)` — **1 line** | 3-4 clicks, check boxes |\n",
    "| Tukey HSD | `tukey_hsd(g1, g2, ...)` — **1 line** | Check post-hoc options |\n",
    "| 28 pairwise tests | Loop: 10 lines total | Click 28x through menus |\n",
    "\n",
    "The tests are equally simple. **But Python can do things JASP cannot.** We demonstrated:\n",
    "- Automation (loop through all comparisons)\n",
    "- Custom publication-quality visualizations\n",
    "- Bootstrap confidence intervals\n",
    "- Complete reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: The Python Cheat Sheet\n",
    "\n",
    "| What you want to do | Python code |\n",
    "|---|---|\n",
    "| Load Excel data | `df = pd.read_excel('file.xlsx')` |\n",
    "| Load CSV data | `df = pd.read_csv('file.csv')` |\n",
    "| View first rows | `df.head()` |\n",
    "| Check data structure | `df.info()` |\n",
    "| Check for missing values | `df.isna().sum()` |\n",
    "| Group means | `df.groupby('Group')['DV'].mean()` |\n",
    "| Descriptive stats | `df.groupby('Group')['DV'].agg(['count', 'mean', 'std'])` |\n",
    "| Independent t-test | `stats.ttest_ind(group1, group2)` |\n",
    "| Welch's t-test | `stats.ttest_ind(group1, group2, equal_var=False)` |\n",
    "| Paired t-test | `stats.ttest_rel(pre, post)` |\n",
    "| Levene's test | `stats.levene(group1, group2)` |\n",
    "| One-way ANOVA | `stats.f_oneway(g1, g2, g3, ...)` |\n",
    "| Tukey HSD | `tukey_hsd(g1, g2, g3, ...)` |\n",
    "| Mixed ANOVA (repeated measures) | `pg.mixed_anova(data=df, dv='Score', within='Time', between='Group', subject='Subject')` |\n",
    "| Histogram | `plt.hist(x, bins=10, color='blue')` |\n",
    "| Swarm plot | `sns.swarmplot(data=df, x='Group', y='Value')` |\n",
    "| Bar plot | `plt.bar(x, heights, yerr=errors)` |\n",
    "\n",
    "**That's it.** With these functions, you can do everything JASP does — and much more.\n",
    "\n",
    "You don't have to memorize them. There is no test. The more you use them, the more you will remember.\n",
    "\n",
    "**Remember:** The skills you learned today transfer directly to machine learning, neuroimaging, bioinformatics, and countless other fields!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a85242-9331-4ef9-9128-32e25a1bb6d8",
   "metadata": {},
   "source": [
    "For more, check out this great talk on why data science (and statistics in general) is better when done with code instead of with a GUI:\n",
    "\n",
    "\n",
    "https://www.youtube.com/watch?v=cpbtcsGE0OA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c154d5-f9ff-4816-a741-940d9696fbb5",
   "metadata": {},
   "source": [
    "It's a long video, but you can find a summary of the key points here \n",
    "\n",
    "https://asterisk.dynevor.org/you-cant-do-data-science-in-a-gui.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vy3cs1wy2f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Challenge: Try Your Own Data\n",
    "\n",
    "Want to practice with your own data?\n",
    "\n",
    "**In Google Colab:**\n",
    "1. Click the folder icon on the left sidebar\n",
    "2. Click the upload button (page with up arrow)\n",
    "3. Select your Excel or CSV file\n",
    "4. Load it with:\n",
    "\n",
    "```python\n",
    "my_df = pd.read_excel('your_file.xlsx')  # for Excel\n",
    "# or\n",
    "my_df = pd.read_csv('your_file.csv')     # for CSV\n",
    "```\n",
    "\n",
    "5. Explore it:\n",
    "```python\n",
    "my_df.head()\n",
    "my_df.info()\n",
    "my_df.columns\n",
    "```\n",
    "\n",
    "You now have all the tools to analyze it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34901940-24b8-442a-8eb2-8f50b803073e",
   "metadata": {},
   "source": [
    "You can also load up the `spotify.csv` dataset which I have uploaded here. Play around. See what you find. This is one of the best ways to learn Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1e0c5a-0a44-4d45-99b1-48ce0793d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it up\n",
    "spotify = ...\n",
    "\n",
    "# Then peek at the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663eabf8-ecb0-436c-99db-df168eb3dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at your columns of spotify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc77188e-d20a-4f60-bfda-8a80dd815ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the unique values of column track_genre\n",
    "spotify.track_genre.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84a9bd-1aa0-44ac-abf1-3d9c64c4acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the unique values of column artists\n",
    "# :50 prints the first 50\n",
    "spotify.artists.unique()[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577b20ce-38ee-4e03-88f2-c372738a7f93",
   "metadata": {},
   "source": [
    "Here's how you can get an artist's songs. \n",
    "\n",
    "You have to be careful here because multiple artists can be listed under `artists`. So we use the `.str.contains` method, and make sure that we aren't being cAsE sEnSiTive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a324f-2995-4f63-ad02-d87295ecedfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kid_cudi_songs = spotify[spotify['artists'].str.contains('kid cudi', case=False, na=False)]\n",
    "kid_cudi_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffb9589-d67a-490f-8951-ec84876c2db7",
   "metadata": {},
   "source": [
    "let's wrap this into a function to make it easier for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39059ab8-cde2-42cc-b952-a5e64c78f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist_songs(artist_name):\n",
    "    return spotify[spotify['artists'].str.contains(artist_name, case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee384ea2-fa63-4e01-8dd6-8defba055ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "sabrina = get_artist_songs(\"sabrina carpenter\")\n",
    "sabrina.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7481ca0-715e-4e76-b0cf-b72b18ea5efa",
   "metadata": {},
   "source": [
    "Here is a simple function you can use to extract the a column for all songs of a given `genre`.\n",
    "\n",
    "For example, if you want to save the `danceability` of `reggaeton`, you can use \n",
    "```\n",
    "reggaeton_dance = get_genre_values(\"reggaeton\", \"danceability\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a3a4be-4584-470d-b19d-9fdb205606b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genre_values(genre, value_name):\n",
    "    return spotify[spotify.track_genre==genre][value_name].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fde75c-4ba6-4348-a0cd-922c8d892662",
   "metadata": {},
   "outputs": [],
   "source": [
    "reggaeton_dance = get_genre_values(\"reggaeton\", \"danceability\")\n",
    "reggaeton_dance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58f6052-6458-4131-a885-eb5469991792",
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic = get_genre_values(\"acoustic\", \"danceability\")\n",
    "acoustic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eeae10-eaf2-4fa8-aa89-a5f8d9a5cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "turkish = get_genre_values(\"turkish\", \"danceability\")\n",
    "party = get_genre_values(\"party\", \"danceability\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47480b5c-fdf4-4c6f-9e77-21bd1ebc5719",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(turkish, label='turkish', bins=30, alpha=.5)\n",
    "plt.hist(party, label='party', bins=30, alpha=.5)\n",
    "plt.hist(reggaeton_dance, label='reggaeton_dance', bins=30, alpha=.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df22e3e4-c843-4abf-ac8b-4ef657d1c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic = spotify[spotify.track_genre=='acoustic'].danceability.values\n",
    "gospel = spotify[spotify.track_genre=='gospel'].danceability.values\n",
    "plt.hist(acoustic, label='acoustic')\n",
    "plt.hist(gospel, label='gospel')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4494cab-a2f1-4022-8617-f960f0c8d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(spotify.popularity, spotify.danceability, alpha=.1, c=spotify.valence)\n",
    "plt.xlabel(\"popularity\")\n",
    "plt.ylabel(\"Danceability\")\n",
    "plt.colorbar(label=\"valence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c67373-db7d-4473-8bfa-8d742afca6dd",
   "metadata": {},
   "source": [
    "What else can you do? Try some stuff out. Feel free to use the above examples and functions to explore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c556525b-bd70-48b8-a5e8-c28a01c5a2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
