{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Reproducibility Lab: Functional Connectivity and Behavior\n",
    "\n",
    "## EXPLORATORY ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objectives",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "- Explore functional connectivity data from a real brain atlas (216 regions, 23,220 edges)\n",
    "- Test brain-behavior relationships across thousands of connectivity edges\n",
    "- Discover how analytic flexibility affects statistical findings\n",
    "- Validate your findings in an independent dataset\n",
    "- Present your strongest discoveries to the class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "background",
   "metadata": {},
   "source": [
    "## Background: Functional Connectivity\n",
    "\n",
    "**Functional connectivity (FC)** measures how correlated the activity is between two brain regions during a resting-state fMRI scan. When two regions show correlated activity over time, we say they are \"functionally connected.\"\n",
    "\n",
    "In this lab, you have FC data from a brain atlas with **216 regions of interest (ROIs)** organized into **8 brain networks**. For every pair of ROIs, we have a connectivity value for each subject -- that gives us **23,220 unique edges** (connections) to analyze.\n",
    "\n",
    "Your goal is to find edges whose connectivity strength predicts individual differences in a behavioral outcome (pain sensitivity, depression severity, or anxiety level, depending on your assigned topic).\n",
    "\n",
    "### Brain Networks\n",
    "\n",
    "The 216 ROIs are organized into networks based on the Schaefer 200-parcel cortical atlas plus Tian subcortical atlas:\n",
    "\n",
    "| Network | Description |\n",
    "|---------|------------|\n",
    "| Subcortical | Hippocampus, amygdala, thalamus, basal ganglia |\n",
    "| Visual | Central and peripheral visual areas |\n",
    "| Somatomotor | Primary motor and somatosensory cortex |\n",
    "| Dorsal Attention | Top-down attention control (focusing on tasks) |\n",
    "| Salience | Detecting important stimuli, switching between networks |\n",
    "| Limbic | Emotion processing, memory |\n",
    "| Frontoparietal | Executive function, cognitive control |\n",
    "| Default Mode | Self-referential thought, mind-wandering |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "topic-setup",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Set Your Topic\n",
    "\n",
    "Your instructor has assigned you one of three topics. Set the `TOPIC` variable below to match your assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "set-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET YOUR TOPIC HERE (change this to match your assignment)\n",
    "# Options: 'pain', 'depression', or 'anxiety'\n",
    "\n",
    "TOPIC = 'depression'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Part 2: Setup and Load Data\n",
    "\n",
    "Run the cells below to download the data files and load your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-downloads",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages for brain visualizations and statistical corrections\n",
    "import subprocess, sys\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'nilearn', 'statsmodels', '-q'])\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "base_url = 'https://raw.githubusercontent.com/cmahlen/python-stats-demo/main/'\n",
    "files_needed = [\n",
    "    'lab_helpers.py',\n",
    "    'atlas_labels.txt',\n",
    "    'data/roi_mni_coords.npy',\n",
    "    f'data/{TOPIC}_discovery.npz',\n",
    "    f'data/{TOPIC}_validation.npz',\n",
    "]\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "for f in files_needed:\n",
    "    if not os.path.exists(f):\n",
    "        print(f'Downloading {f}...')\n",
    "        urllib.request.urlretrieve(base_url + f, f)\n",
    "\n",
    "print('Setup complete!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab_helpers as helpers\n",
    "\n",
    "# Load the discovery dataset\n",
    "helpers.load_dataset(TOPIC, 'discovery')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5hu4hwe7yy",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Peek at the Data\n",
    "\n",
    "Before running any statistical tests, let's look at what we actually have. This is a crucial first step in any analysis -- understand your data before analyzing it.\n",
    "\n",
    "First, let's see what variables are available and what they measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o7q6k2m6az",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What variables do we have? Print descriptions and units for each one.\n",
    "helpers.describe_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ne5yqjj9ak",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the first few rows of behavioral data\n",
    "# Each row is one subject; columns are their scores on different measures\n",
    "behavior = helpers.get_behavior()\n",
    "behavior = behavior.astype(float).round(3)\n",
    "behavior.head().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wzj045j6i2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for all variables\n",
    "# Look at the mean, standard deviation, min, and max for each variable\n",
    "behavior.describe().round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahf8yfzm83a",
   "metadata": {},
   "source": [
    "Each row in the `behavior` datafrmae is one subject. You have behavioral outcome scores and several demographic/clinical variables.\n",
    "\n",
    "**Tip:** To get a single column as its own variable, use square brackets: `behavior['PHQ9']` or `behavior['Age']`. You can also use `helpers.get_behavior('PHQ9')` directly.\n",
    "\n",
    "The brain connectivity data is stored separately. For every pair of brain regions, you have a **connectivity value** for each subject -- a number telling you how correlated those two regions' activity was during a brain scan. Let's look at what one of those values looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4y8gdezb3p",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the connectivity values between the hippocampus and amygdala\n",
    "# ROI names use abbreviations: HIP = hippocampus, AMY = amygdala\n",
    "# The suffix tells you the hemisphere: lh = left, rh = right\n",
    "edge = helpers.get_edge('HIP-lh', 'AMY-rh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d5be5b-9588-48c4-963b-b20af0e11b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1xnbxmvn3sh",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Visualize Before Testing\n",
    "\n",
    "Before running any statistical tests, always plot your data first. Visualizations help you spot patterns, outliers, and potential problems that numbers alone might miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tgdpfirxs6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The first column is always the main outcome variable for your topic\n",
    "OUTCOME = behavior.columns[0]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(behavior[OUTCOME], bins=20, color='steelblue', edgecolor='black')\n",
    "plt.xlabel(OUTCOME)\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Distribution of {OUTCOME} (n = {len(behavior)})')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"This shows how {OUTCOME} is distributed across your {len(behavior)} subjects.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explore-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Explore the Brain Networks\n",
    "\n",
    "Now that you have a sense of the data, let's explore the brain networks and regions available to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list-networks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What brain networks are available?\n",
    "helpers.list_networks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list-regions-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What regions are in a specific network?\n",
    "# Try changing the network name to explore different ones\n",
    "helpers.list_regions('Salience')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ojspijl91g",
   "metadata": {},
   "source": [
    "You can also visualize the connectivity within a specific network using `helpers.plot_network_matrix()`:\n",
    "\n",
    "```python\n",
    "helpers.plot_network_matrix('Default Mode')\n",
    "helpers.plot_network_matrix('Subcortical')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ehl2lg4mep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Turn: try visualizing different networks here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35iw9x2nc5w",
   "metadata": {},
   "source": [
    "### Understanding ROI Names\n",
    "\n",
    "The region names follow a naming convention. Here's how to decode a cortical ROI name:\n",
    "\n",
    "```\n",
    "LH_SalVentAttnA_Ins_1\n",
    "│   │             │   │\n",
    "│   │             │   └── parcel number (multiple parcels per subregion)\n",
    "│   │             └────── subregion: Ins = Insula\n",
    "│   └──────────────────── sub-network: SalVentAttnA (Salience/Ventral Attention A)\n",
    "└──────────────────────── hemisphere: LH = left, RH = right\n",
    "```\n",
    "\n",
    "The sub-network names (like DefaultA, DefaultB, SalVentAttnA, SalVentAttnB, etc.) come from the Schaefer atlas, which defined 17 fine-grained sub-networks. For simplicity, we group these into **8 broader display networks** (Default Mode, Salience, etc.) that you saw in `list_networks()`. The sub-network names are still visible in the ROI names and can be useful for more targeted analyses.\n",
    "\n",
    "Subcortical regions use shorter names like `HIP-lh` (left hippocampus) or `NAc-rh` (right nucleus accumbens).\n",
    "\n",
    "Use `helpers.describe_regions()` to see decoded descriptions for all regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i79v0ayk8xg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See decoded region names for any network\n",
    "helpers.describe_regions('Subcortical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-connectome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the overall connectivity structure\n",
    "# This heatmap shows which networks tend to be connected to each other\n",
    "helpers.plot_connectome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hfm6d0u3qe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now visualize the relationship between one brain edge and your outcome\n",
    "# plot_edge() makes a scatter plot with a regression line\n",
    "helpers.plot_edge('HIP-lh', 'AMY-rh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zyiugsw6db",
   "metadata": {},
   "source": [
    "Each dot is one subject. The x-axis shows connectivity strength between those two regions, and the y-axis shows their behavioral score. The line shows the best linear fit, and the **r** and **p** values tell you how strong the relationship is and whether it's statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kkveabwzu4",
   "metadata": {},
   "source": [
    "### Understanding Correlation (Pearson r)\n",
    "\n",
    "Every scatter plot above shows a **Pearson r** value. This measures the strength of the linear relationship between two variables:\n",
    "\n",
    "- **r = +1.0**: perfect positive relationship (as one goes up, the other always goes up)\n",
    "- **r = 0.0**: no linear relationship\n",
    "- **r = -1.0**: perfect negative relationship (as one goes up, the other always goes down)\n",
    "\n",
    "In brain-behavior research, correlations are usually small:\n",
    "- |r| < 0.10 — negligible\n",
    "- |r| around 0.10–0.20 — small\n",
    "- |r| around 0.20–0.30 — medium\n",
    "- |r| > 0.30 — large (rare in neuroimaging)\n",
    "\n",
    "Another useful way to think about it: **r-squared** (r x r) tells you the proportion of variance explained. An r of 0.20 means r-squared = 0.04, so the brain connection explains about 4% of the individual differences in the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5tfd57aco74",
   "metadata": {},
   "source": [
    "### Your Turn: Explore Different Edges and Variables\n",
    "\n",
    "Try plotting different brain regions against different behavioral variables. You can change the region names and add a `behavior_col` argument to `plot_edge()`.\n",
    "\n",
    "<details>\n",
    "<summary>Hint: Example code</summary>\n",
    "\n",
    "```python\n",
    "# Plot a different pair of regions\n",
    "helpers.plot_edge('NAc-rh', 'AMY-lh')\n",
    "\n",
    "# Plot against a different behavioral variable (e.g., 'Age', 'Stress_Level', 'HRV')\n",
    "helpers.plot_edge('HIP-lh', 'AMY-rh', behavior_col='Stress_Level')\n",
    "\n",
    "# Plot against another variable to see if the same edge predicts different things\n",
    "helpers.plot_edge('HIP-lh', 'AMY-rh', behavior_col='Age')\n",
    "```\n",
    "\n",
    "Use `helpers.list_regions('Subcortical')` to see available region names.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ajf6wmmusvr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Turn: try different behavioral variables here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "testing-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Test Brain-Behavior Relationships\n",
    "\n",
    "Now let's systematically test whether any brain connections predict your behavioral outcome. With 23,220 edges to test, we need to think carefully about which ones to focus on and how to handle false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mass-testing-header",
   "metadata": {},
   "source": [
    "### From Individual Edges to Mass Testing\n",
    "\n",
    "You've looked at a few edges by hand. But there are **23,220 edges** in this dataset. Testing them one by one would take forever.\n",
    "\n",
    "Let's test them all at once and find the ones with the strongest correlations.\n",
    "\n",
    "**Quick thought experiment:** If there were NO real brain-behavior relationships at all -- if every edge were pure random noise -- how many would you expect to be \"significant\" at p < 0.05? (Keep your guess in mind as you look at the results.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-all-edges",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ALL edges vs your outcome variable\n",
    "results = helpers.test_all_edges()\n",
    "\n",
    "# Show the top 20 findings\n",
    "print(\"\\nTop 20 findings (sorted by p-value):\")\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "count-significant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many edges are \"significant\"?\n",
    "n_sig = (results['p'] < 0.05).sum()\n",
    "n_total = len(results)\n",
    "print(f\"Significant at p < 0.05: {n_sig:,} out of {n_total:,} edges\")\n",
    "print(f\"That's {n_sig/n_total*100:.1f}% of all edges tested\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-top-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize your strongest finding\n",
    "top = results.iloc[0]\n",
    "helpers.plot_edge(top['ROI_A'], top['ROI_B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6t26ztbjn6q",
   "metadata": {},
   "source": [
    "### Visualize Your Findings on a Glass Brain\n",
    "\n",
    "A \"glass brain\" plot shows brain connections drawn on a transparent brain template. Each colored dot is a brain region (colored by network), and each line is a significant connection. Red lines indicate positive correlations; blue lines indicate negative correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "glass-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize your top findings on a glass brain\n",
    "helpers.plot_glass_brain(results, n_top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threshold-header",
   "metadata": {},
   "source": [
    "### The Multiple Comparisons Problem\n",
    "\n",
    "When you test 23,220 edges, some will be \"significant\" purely by chance. At p < 0.05, you expect about 5% of tests to be false positives -- even if there are NO real effects at all. Let's see what this looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threshold-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_tests = len(results)\n",
    "alpha = 0.05\n",
    "expected_fp = n_tests * alpha\n",
    "actual_sig = (results['p'] < 0.05).sum()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"THE MULTIPLE COMPARISONS PROBLEM\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nYou tested {n_tests:,} edges at p < {alpha}\")\n",
    "print(f\"Expected FALSE POSITIVES by chance alone: ~{expected_fp:,.0f}\")\n",
    "print(f\"Actual 'significant' findings: {actual_sig:,}\")\n",
    "print(f\"\\nMost of those are likely noise, not real brain-behavior relationships!\")\n",
    "\n",
    "# Visualize the p-value distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(results['p'], bins=50, edgecolor='black', color='steelblue')\n",
    "plt.axvline(0.05, color='coral', linestyle='--', linewidth=2, label='p = 0.05')\n",
    "plt.xlabel('P-value')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Distribution of P-values Across {len(results):,} Edge Tests')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lavmt7d9krl",
   "metadata": {},
   "source": [
    "If there were NO real effects, the histogram would be perfectly flat (uniform). Any bump near 0 suggests some real signal -- but most of those \"significant\" edges at p < 0.05 are still false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-comp-header",
   "metadata": {},
   "source": [
    "### Correction Methods: Bonferroni and FDR\n",
    "\n",
    "There are standard statistical methods to correct for multiple comparisons:\n",
    "\n",
    "- **Bonferroni correction**: Divide your significance threshold by the number of tests. With 23,220 tests, the threshold becomes 0.05 / 23,220 = 0.0000022. Very strict -- controls the chance of ANY false positive.\n",
    "- **FDR (False Discovery Rate)**: Controls the expected PROPORTION of false positives among your significant results. Less strict than Bonferroni -- allows more true positives through, at the cost of tolerating a small fraction of false positives.\n",
    "\n",
    "Let's apply both corrections to our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-comp-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We already ran test_all_edges() above. Let's apply corrections to those results.\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import numpy as np\n",
    "\n",
    "n_tests = len(results)\n",
    "\n",
    "# Bonferroni: multiply each p-value by the number of tests\n",
    "results_bonf = results.copy()\n",
    "results_bonf['p_corrected'] = np.minimum(results['p'] * n_tests, 1.0)\n",
    "n_bonf = (results_bonf['p_corrected'] < 0.05).sum()\n",
    "\n",
    "# FDR (Benjamini-Hochberg): less strict, controls the proportion of false discoveries\n",
    "_, p_fdr, _, _ = multipletests(results['p'].values, alpha=0.05, method='fdr_bh')\n",
    "results_fdr = results.copy()\n",
    "results_fdr['p_corrected'] = p_fdr\n",
    "n_fdr = (results_fdr['p_corrected'] < 0.05).sum()\n",
    "\n",
    "n_uncorrected = (results['p'] < 0.05).sum()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SUMMARY: Corrections applied to all {:,} edges\".format(n_tests))\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Uncorrected p < 0.05:     {n_uncorrected:,}\")\n",
    "print(f\"  Surviving Bonferroni:     {n_bonf}\")\n",
    "print(f\"  Surviving FDR:            {n_fdr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h24x2ljohc",
   "metadata": {},
   "source": [
    "With this many tests, even FDR is very strict. Is there a way to get a gentler correction?\n",
    "\n",
    "Yes -- by testing fewer edges. If you can narrow your search to a specific brain network, you reduce the number of tests and make correction much more manageable. This is a legitimate scientific strategy: in real research, you're expected to have a hypothesis *before* collecting data. If you have a reason to focus on a particular network (based on prior literature), it makes sense to only test those edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t5e4alzjb2",
   "metadata": {},
   "source": [
    "### Narrow Your Hypothesis: Focus on a Specific Network\n",
    "\n",
    "Here's the key insight: the correction penalty depends on **how many tests you run**. If instead of testing all 23,220 edges, you focus on a specific brain network, you only test ~200-500 edges. That means a much gentler correction.\n",
    "\n",
    "This is a legitimate scientific approach -- you can argue that you have a reason to focus on a particular network (e.g., \"the default mode network is involved in rumination and depression\" or \"subcortical regions process pain and emotion\").\n",
    "\n",
    "Let's try two approaches: first, test all edges **involving** a network (where at least one ROI is in the network), and then test edges **within** a network (where both ROIs are in the network):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all edges INVOLVING a specific network (at least one ROI in the network)\n",
    "# This tests ~200-500 edges depending on the network\n",
    "network_results = helpers.test_network_edges('Subcortical', correction='fdr')\n",
    "\n",
    "# How many survive FDR correction?\n",
    "n_survive = (network_results['p_corrected'] < 0.05).sum()\n",
    "print(f\"\\nFindings surviving FDR correction: {n_survive}\")\n",
    "\n",
    "if n_survive > 0:\n",
    "    print(\"\\nFDR-corrected significant edges:\")\n",
    "    print(network_results[network_results['p_corrected'] < 0.05][\n",
    "        ['ROI_A', 'ROI_B', 'r', 'p', 'p_corrected']\n",
    "    ].to_string())\n",
    "else:\n",
    "    print(\"No edges survived FDR correction -- still too many tests.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w6c3t6h67fg",
   "metadata": {},
   "source": [
    "You may find that few or no edges survive FDR correction here -- even with fewer tests, the \"involving\" search still includes hundreds of edges. There's a way to narrow further: test only edges **within** a network (where both ROIs belong to the same network) instead of edges **involving** a network (where at least one ROI belongs to it). This cuts the number of tests down to ~50-120 edges per network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p3lu4tm28q",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we test ONLY edges WITHIN a network?\n",
    "# This tests ~50-120 edges -- much fewer tests, much gentler correction\n",
    "within_results = helpers.test_network_edges('Subcortical', correction='fdr', within=True)\n",
    "\n",
    "# How many survive FDR correction?\n",
    "n_survive = (within_results['p_corrected'] < 0.05).sum()\n",
    "print(f\"\\nFindings surviving FDR correction: {n_survive}\")\n",
    "\n",
    "# Let's see the best results even if they don't quite survive\n",
    "print(\"\\nTop 10 within-network edges (sorted by corrected p-value):\")\n",
    "print(within_results.head(10)[['ROI_A', 'ROI_B', 'r', 'p', 'p_corrected']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6uoxrf2",
   "metadata": {},
   "source": [
    "By narrowing to edges *within* a single network, the correction penalty is much smaller. You may see some results that are close to surviving FDR correction but not quite there.\n",
    "\n",
    "In the next section, you'll learn tools that researchers use to refine results like these -- controlling for confounding variables, handling outliers, and analyzing subgroups. These techniques can push marginal results over the significance threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bjg25mjf9s",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Your Analysis Toolkit -- Refining Results\n",
    "\n",
    "You've found some promising within-network results that are close to significance after FDR correction. Now let's learn tools that researchers use to refine their analyses. Each tool is a legitimate analytical technique -- but they also give you flexibility in how you analyze your data.\n",
    "\n",
    "All of these tools work with both `plot_edge()` and the mass testing functions (`test_all_edges()`, `test_network_edges()`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trjyeg4adpt",
   "metadata": {},
   "source": [
    "### Covariates: Controlling for Confounding Variables\n",
    "\n",
    "A **covariate** is a variable you account for (\"control for\") to see whether a relationship still holds after removing its influence. When you control for a variable, the axes show \"residualized\" values -- what's left of each variable after statistically removing the influence of the covariate.\n",
    "\n",
    "**Why does this matter?** Sometimes two variables look related, but the apparent relationship is actually driven by a third variable. Let's see an example with the behavioral data first, then apply the same logic to brain data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qws505pudoq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are sleep quality and social media use related?\n",
    "helpers.plot_behavior('Sleep_Quality', 'Social_Media')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc2fffe-3edb-468d-bd27-56915fd1dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hmm, there's a correlation. But could something else be driving both?\n",
    "# People who spend more time on screens might BOTH sleep worse AND use more social media.\n",
    "# Let's control for Screen_Time and see what happens:\n",
    "helpers.plot_behavior('Sleep_Quality', 'Social_Media', covariates=['Screen_Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ooyyoa8zl",
   "metadata": {},
   "source": [
    "Notice how the correlation changed after controlling for Screen_Time. Screen time appears to be a **confounding variable** driving both sleep quality and social media use. The same principle applies to brain data -- let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvp8y56xh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does this Frontoparietal-Salience edge predict GAD7?\n",
    "helpers.plot_edge('LH_ContB_PFCl_1', 'RH_SalVentAttnA_Ins_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1437ac93-197f-4f72-9230-4a2c6c78cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now control for Stress_Level and see what happens:\n",
    "helpers.plot_edge('LH_ContB_PFCl_1', 'RH_SalVentAttnA_Ins_1', covariates=['Stress_Level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xp7b2vnpc9b",
   "metadata": {},
   "source": [
    "The amygdala-insula connection tracks stress levels -- and stress is related to the outcome. So this edge *appeared* to predict the outcome, but the relationship was really driven by stress. After controlling for Stress_Level, the correlation weakened or vanished entirely.\n",
    "\n",
    "Covariates can weaken OR strengthen findings. The question is always *which* covariates to include, and whether you chose them before or after seeing your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "we43r8ctyc",
   "metadata": {},
   "source": [
    "### Outlier Handling\n",
    "\n",
    "An **outlier** is a data point that is unusually far from the rest. **Z-scores** measure how many standard deviations (SD) a value is from the mean. A z-score of 2 means roughly the most extreme 5% of data; 3 SD is the most extreme 0.3%.\n",
    "\n",
    "Add an `exclude_outliers` argument to remove extreme connectivity values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ulthmddj5h",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data\n",
    "helpers.plot_edge('HIP-lh', 'AMY-rh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa2422-ea58-4902-9f36-f2b0b93e508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers (> 2 SD from the mean -- the most extreme ~5% of values)\n",
    "helpers.plot_edge('HIP-lh', 'AMY-rh', exclude_outliers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bho3pmqzhoq",
   "metadata": {},
   "source": [
    "Notice how the result changes depending on the outlier threshold. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ar00e30vlqv",
   "metadata": {},
   "source": [
    "### Subgroup Analysis: Effects Can Differ Across Groups\n",
    "\n",
    "Relationships can look different depending on who you include. A finding that exists in one group might not exist in another -- or might even reverse.\n",
    "\n",
    "Let's look at an example: is the relationship between social media use and stress the same for everyone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1otar4se5dr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall relationship between social media and stress\n",
    "helpers.plot_behavior('Social_Media', 'Stress_Level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1e81ea-fd3a-4413-9e9c-cc1c0dcb0d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the relationship differ by sex?\n",
    "helpers.plot_behavior('Social_Media', 'Stress_Level', subgroup={'Sex': 0})  # women\n",
    "helpers.plot_behavior('Social_Media', 'Stress_Level', subgroup={'Sex': 1})  # men"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jh66q7pylk",
   "metadata": {},
   "source": [
    "The overall correlation masks a big difference between groups. This is called **moderation** -- Sex moderates the Social_Media-Stress relationship. The effect looks very different depending on which subgroup you examine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0jyd0qcb8qsh",
   "metadata": {},
   "source": [
    "### Key Takeaway\n",
    "\n",
    "Covariates, subgroups, and outlier handling are all **legitimate analytical tools** that researchers use every day. Each one can reveal effects that would otherwise be hidden -- or rule out effects that aren't real.\n",
    "\n",
    "These tools all work with the mass testing functions too. For example:\n",
    "```python\n",
    "# Test within-network edges with covariates and FDR correction\n",
    "helpers.test_network_edges('Default Mode', covariates=['Age'], correction='fdr', within=True)\n",
    "\n",
    "# Test within a subgroup\n",
    "helpers.test_network_edges('Subcortical', subgroup={'Sex': 0}, correction='fdr', within=True)\n",
    "```\n",
    "\n",
    "You now have a full toolkit for exploring brain-behavior relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5hvha403hi",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Your Task: Find Significant Brain-Behavior Relationships!\n",
    "\n",
    "Now that you have the tools, your goal is to **discover which functional connections predict your outcome variable**.\n",
    "\n",
    "### Extra Credit Opportunity!\n",
    "\n",
    "**<span style=\"color: red;\">The student who finds the strongest, most compelling brain-behavior relationships will receive extra credit.</span>** Strong findings are:\n",
    "- Statistically significant (low p-values)\n",
    "- Large effect sizes (strong correlations)\n",
    "- Well-visualized and clearly presented\n",
    "\n",
    "Be creative and thorough! Use any of the techniques you learned in Parts 6 and 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "workspace-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Your Workspace\n",
    "\n",
    "Use the cells below to explore further and build your case for the strongest findings.\n",
    "\n",
    "Your goal: find brain-behavior relationships that **survive FDR correction** within a specific network. You have many tools at your disposal:\n",
    "\n",
    "- Test within a network: `helpers.test_network_edges('Default Mode', correction='fdr', within=True)`\n",
    "- Add covariates: `helpers.test_network_edges('Default Mode', covariates=['Age'], correction='fdr', within=True)`\n",
    "- Exclude outliers: `helpers.test_network_edges('Limbic', exclude_outliers=2, correction='fdr', within=True)`\n",
    "- Analyze subgroups: `helpers.test_network_edges('Salience', subgroup={'Sex': 0}, correction='fdr', within=True)`\n",
    "- Plot a specific finding: `helpers.plot_edge(top['ROI_A'], top['ROI_B'])`\n",
    "- Explore behavior relationships: `helpers.plot_behavior('Stress_Level', 'Sleep_Quality')`\n",
    "- Visualize on glass brain: `helpers.plot_glass_brain(network_results)`\n",
    "\n",
    "Most students try 5-10 different network/covariate/subgroup combinations before finding something that survives FDR. This is normal -- keep exploring!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "workspace-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try testing WITHIN a specific network with FDR correction:\n",
    "network_results = helpers.test_network_edges('Default Mode', correction='fdr', within=True)\n",
    "\n",
    "# Show any FDR-corrected significant edges\n",
    "fdr_sig = network_results[network_results['p_corrected'] < 0.05]\n",
    "if len(fdr_sig) > 0:\n",
    "    print(f\"\\n{len(fdr_sig)} edges survived FDR correction!\")\n",
    "    print(fdr_sig[['ROI_A', 'ROI_B', 'r', 'p', 'p_corrected']].to_string())\n",
    "else:\n",
    "    print(\"\\nNo edges survived FDR correction. Try a different network, add covariates, or try a subgroup!\")\n",
    "\n",
    "network_results\n",
    "    \n",
    "# Try other networks or add refinements:\n",
    "# helpers.test_network_edges('Salience', correction='fdr', within=True)\n",
    "# helpers.test_network_edges('Subcortical', correction='fdr', within=True)\n",
    "# helpers.test_network_edges('Frontoparietal', covariates=['Age'], correction='fdr', within=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "workspace-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot your top finding, or explore further:\n",
    "# top = network_results.iloc[0]\n",
    "# helpers.plot_edge(top['ROI_A'], top['ROI_B'])\n",
    "\n",
    "# Visualize on glass brain:\n",
    "# helpers.plot_glass_brain(network_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fp7e4t94pi4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your exploration here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x0q7z3zluml",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Prepare Your Presentation\n",
    "\n",
    "For next class, prepare a brief presentation (5-7 minutes) covering:\n",
    "\n",
    "1. **Your approach**\n",
    "   - What networks did you focus on, and why?\n",
    "   - What analysis decisions did you make (covariates, outliers, subgroups)?\n",
    "\n",
    "2. **Your top findings**\n",
    "   - Which brain-behavior relationships survived FDR correction?\n",
    "   - Show visualizations (scatter plots, glass brain)\n",
    "   - Report statistics (r values, uncorrected and corrected p-values)\n",
    "\n",
    "3. **Why you believe your findings**\n",
    "   - What makes you confident these are real effects?\n",
    "   - Do the brain regions involved make sense for your topic?\n",
    "\n",
    "4. **How would you convince a skeptic?**\n",
    "   - What evidence would you point to?\n",
    "   - What concerns might someone raise?\n",
    "\n",
    "**Saving figures:** To save any figure for your presentation, add this line before `plt.show()`:\n",
    "```python\n",
    "plt.savefig('my_figure.png', dpi=150, bbox_inches='tight')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zr00huo6a28",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# DAY 2 STARTS HERE\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llyricgl089",
   "metadata": {},
   "source": [
    "**Important:** If your Colab runtime disconnected since Day 1, run the cells below to reload everything before continuing. If your runtime is still active, you can skip these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ujvx6vvzkiq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 2 Setup: Re-run if your runtime disconnected\n",
    "# (If your runtime is still active from Day 1, you can skip this cell)\n",
    "\n",
    "import subprocess, sys\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'nilearn', 'statsmodels', '-q'])\n",
    "\n",
    "import os, urllib.request\n",
    "base_url = 'https://raw.githubusercontent.com/cmahlen/python-stats-demo/main/'\n",
    "files_needed = [\n",
    "    'lab_helpers.py', 'atlas_labels.txt', 'data/roi_mni_coords.npy',\n",
    "    f'data/{TOPIC}_discovery.npz', f'data/{TOPIC}_validation.npz',\n",
    "]\n",
    "os.makedirs('data', exist_ok=True)\n",
    "for f in files_needed:\n",
    "    if not os.path.exists(f):\n",
    "        urllib.request.urlretrieve(base_url + f, f)\n",
    "\n",
    "import lab_helpers as helpers\n",
    "helpers.load_dataset(TOPIC, 'discovery')\n",
    "\n",
    "# Regenerate your discovery results\n",
    "results = helpers.test_all_edges()\n",
    "print(f\"\\nReloaded! {(results['p'] < 0.05).sum():,} significant edges at p < 0.05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tofob2vbo19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 10: Reflection Questions\n",
    "\n",
    "Before we look at the validation data, take a moment to think about these questions:\n",
    "\n",
    "1. **How confident are you that your FDR-corrected discoveries are real?**\n",
    "   - What would make you more or less confident?\n",
    "\n",
    "2. **The multiple comparisons problem**\n",
    "   - You narrowed from 23,220 edges to a specific network to get a gentler FDR correction. Is that the whole story?\n",
    "   - How many different networks, covariates, and subgroups did you try before finding something that survived correction?\n",
    "   - Does the FDR correction account for ALL the tests you actually ran?\n",
    "\n",
    "3. **Analytic flexibility**\n",
    "   - How many different analysis configurations did you try?\n",
    "   - If you tried multiple approaches, which results did you choose to present and why?\n",
    "\n",
    "4. **The extra credit incentive**\n",
    "   - Did the extra credit incentive affect your analysis decisions?\n",
    "   - Did you feel pressure to find results that survived FDR correction?\n",
    "   - How is this similar to pressures in real academic research?\n",
    "\n",
    "5. **Effect sizes**\n",
    "   - How strong were the correlations you found (r values)?\n",
    "   - Are these large enough to be practically meaningful?\n",
    "\n",
    "Let's discuss these briefly before moving on to the validation test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 11: CRITICAL - Validation Testing\n",
    "\n",
    "### Do your discoveries replicate in independent data?\n",
    "\n",
    "This is the gold standard for confirming your results. Load the **validation set** (a completely independent sample) and test whether your top findings hold up.\n",
    "\n",
    "The code in the next few cells is more complex than what you've been writing. You don't need to understand every line -- just run the cells and focus on the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the validation dataset\n",
    "helpers.load_dataset(TOPIC, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your top 5 discoveries in the validation set\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "top_5 = results.head(5)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"VALIDATION TESTING: Do your top discoveries replicate?\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "validation_results = []\n",
    "for _, row in top_5.iterrows():\n",
    "    edge_vals = helpers.get_edge(row['ROI_A'], row['ROI_B'])\n",
    "    val_behavior = helpers.get_behavior()\n",
    "    outcome_col = val_behavior.columns[0]\n",
    "    val_outcome = val_behavior[outcome_col].values\n",
    "\n",
    "    r_val, p_val = pearsonr(edge_vals, val_outcome)\n",
    "\n",
    "    # Check both significance AND direction (sign of r must match)\n",
    "    same_direction = (r_val * row['r']) > 0\n",
    "    if p_val < 0.05 and same_direction:\n",
    "        replicated = 'YES'\n",
    "    elif p_val < 0.05 and not same_direction:\n",
    "        replicated = 'FLIPPED'\n",
    "    else:\n",
    "        replicated = 'NO'\n",
    "\n",
    "    validation_results.append({\n",
    "        'ROI_A': row['ROI_A'],\n",
    "        'ROI_B': row['ROI_B'],\n",
    "        'Discovery_r': row['r'],\n",
    "        'Discovery_p': row['p'],\n",
    "        'Validation_r': r_val,\n",
    "        'Validation_p': p_val,\n",
    "        'Replicated': replicated,\n",
    "    })\n",
    "\n",
    "val_df = pd.DataFrame(validation_results)\n",
    "val_df.index = range(1, len(val_df) + 1)\n",
    "print(\"\\n\", val_df.to_string())\n",
    "\n",
    "n_replicated = (val_df['Replicated'] == 'YES').sum()\n",
    "n_flipped = (val_df['Replicated'] == 'FLIPPED').sum()\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"REPLICATION SUMMARY: {n_replicated} out of 5 top findings replicated\")\n",
    "if n_flipped > 0:\n",
    "    print(f\"WARNING: {n_flipped} finding(s) were significant but in the OPPOSITE direction!\")\n",
    "    print(\"A flipped direction means the effect is not replicating -- it's noise.\")\n",
    "print(f\"{'=' * 80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize discovery vs validation for your top finding\n",
    "# First reload discovery to get those values\n",
    "helpers.load_dataset(TOPIC, 'discovery')\n",
    "top = results.iloc[0]\n",
    "disc_edge = helpers.get_edge(top['ROI_A'], top['ROI_B'])\n",
    "disc_beh = helpers.get_behavior()\n",
    "disc_outcome = disc_beh[disc_beh.columns[0]].values\n",
    "r_disc, p_disc = pearsonr(disc_edge, disc_outcome)\n",
    "\n",
    "# Now load validation\n",
    "helpers.load_dataset(TOPIC, 'validation')\n",
    "val_edge = helpers.get_edge(top['ROI_A'], top['ROI_B'])\n",
    "val_beh = helpers.get_behavior()\n",
    "val_outcome = val_beh[val_beh.columns[0]].values\n",
    "r_val, p_val = pearsonr(val_edge, val_outcome)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# Discovery\n",
    "axes[0].scatter(disc_edge, disc_outcome, alpha=0.5, color='steelblue')\n",
    "z = np.polyfit(disc_edge, disc_outcome, 1)\n",
    "x_line = np.linspace(disc_edge.min(), disc_edge.max(), 100)\n",
    "axes[0].plot(x_line, np.polyval(z, x_line), color='coral', linewidth=2)\n",
    "axes[0].set_xlabel('Functional Connectivity')\n",
    "axes[0].set_ylabel(disc_beh.columns[0])\n",
    "axes[0].set_title(f'Discovery Set\\nr = {r_disc:.3f}, p = {p_disc:.2e}')\n",
    "\n",
    "# Validation\n",
    "axes[1].scatter(val_edge, val_outcome, alpha=0.5, color='mediumseagreen')\n",
    "z = np.polyfit(val_edge, val_outcome, 1)\n",
    "x_line = np.linspace(val_edge.min(), val_edge.max(), 100)\n",
    "axes[1].plot(x_line, np.polyval(z, x_line), color='coral', linewidth=2)\n",
    "axes[1].set_xlabel('Functional Connectivity')\n",
    "axes[1].set_ylabel(val_beh.columns[0])\n",
    "axes[1].set_title(f'Validation Set\\nr = {r_val:.3f}, p = {p_val:.2e}')\n",
    "\n",
    "fig.suptitle(f'{top[\"ROI_A\"]} <-> {top[\"ROI_B\"]}', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if p_val < 0.05:\n",
    "    print(f\"This finding REPLICATED in the validation set!\")\n",
    "else:\n",
    "    print(f\"This finding DID NOT replicate in the validation set.\")\n",
    "    print(\"This suggests it may have been a false positive.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
