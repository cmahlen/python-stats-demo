{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Reproducibility Lab: Functional Connectivity and Depression\n",
    "\n",
    "## HYPOTHESIS-DRIVEN ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objectives",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "- Formulate a hypothesis about brain-behavior relationships based on prior literature\n",
    "- Use analytical tools (covariates, outliers, subgroups) to refine your analysis\n",
    "- Pre-register an analysis plan before seeing your results\n",
    "- Conduct a hypothesis-driven functional connectivity analysis with Bonferroni correction\n",
    "- Validate findings in an independent dataset\n",
    "- Present rigorous, replicable findings to the class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Setup and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup-downloads",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install nilearn for brain visualizations and download data files\n",
    "import subprocess, sys\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'nilearn', '-q'])\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "base_url = 'https://raw.githubusercontent.com/cmahlen/python-stats-demo/main/'\n",
    "files_needed = [\n",
    "    'lab_helpers.py',\n",
    "    'atlas_labels.txt',\n",
    "    'data/roi_mni_coords.npy',\n",
    "    'data/depression_discovery.npz',\n",
    "    'data/depression_validation.npz',\n",
    "]\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "for f in files_needed:\n",
    "    if not os.path.exists(f):\n",
    "        print(f'Downloading {f}...')\n",
    "        urllib.request.urlretrieve(base_url + f, f)\n",
    "\n",
    "print('Setup complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load-dataset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded depression discovery dataset:\n",
      "  200 subjects\n",
      "  216 brain regions (ROIs)\n",
      "  23,220 connectivity edges\n",
      "  Outcome variable: PHQ9\n",
      "  Other variables: Age, Sex, BMI, HRV, Sleep_Quality, Physical_Activity, Caffeine_mg, Stress_Level, Rumination, Loneliness, Social_Support, Neuroticism, Self_Esteem, Alcohol_drinks, Screen_Time, Social_Media, Education_yrs, Income_k\n"
     ]
    }
   ],
   "source": [
    "import lab_helpers as helpers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Load the discovery dataset\n",
    "helpers.load_dataset('depression', 'discovery')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-note",
   "metadata": {},
   "source": [
    "This dataset is split into two halves: a **discovery set** (which you just loaded) and a **validation set** (which you will use on Day 2). You will find your results in the discovery set first, and then test whether they replicate in the validation set -- a completely independent sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peek-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Peek at the Data\n",
    "\n",
    "Before testing your hypothesis, look at the actual data. This is a crucial first step in any analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "describe-variables",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables in the depression dataset:\n",
      "Variable                       Description\n",
      "---------------------------------------------------------------------------\n",
      "PHQ9                           Depression severity (PHQ-9 questionnaire, 0-27)\n",
      "Age                            Age in years\n",
      "Sex                            Biological sex (0 = female, 1 = male)\n",
      "BMI                            Body mass index (kg/m^2)\n",
      "HRV                            Heart rate variability (RMSSD, ms)\n",
      "Sleep_Quality                  Sleep quality (PSQI, 0-21; higher = worse sleep)\n",
      "Physical_Activity              Physical activity (minutes/week)\n",
      "Caffeine_mg                    Caffeine intake (mg/day)\n",
      "Stress_Level                   Perceived stress (PSS, 0-40)\n",
      "Rumination                     Rumination (RRS, 22-88)\n",
      "Loneliness                     Loneliness (UCLA scale, 20-80)\n",
      "Social_Support                 Perceived social support (MSPSS, 12-60)\n",
      "Neuroticism                    Neuroticism (NEO, 0-48)\n",
      "Self_Esteem                    Self-esteem (Rosenberg, 0-30)\n",
      "Alcohol_drinks                 Alcohol consumption (drinks/week)\n",
      "Screen_Time                    Screen time (hours/day)\n",
      "Social_Media                   Social media use (minutes/day)\n",
      "Education_yrs                  Education (years)\n",
      "Income_k                       Household income ($1000/year)\n",
      "\n",
      "19 variables total.\n"
     ]
    }
   ],
   "source": [
    "# What variables do we have? Print descriptions and units for each one.\n",
    "helpers.describe_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "behavior-head",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PHQ9</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BMI</th>\n",
       "      <th>HRV</th>\n",
       "      <th>Sleep_Quality</th>\n",
       "      <th>Physical_Activity</th>\n",
       "      <th>Caffeine_mg</th>\n",
       "      <th>Stress_Level</th>\n",
       "      <th>Rumination</th>\n",
       "      <th>Loneliness</th>\n",
       "      <th>Social_Support</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Self_Esteem</th>\n",
       "      <th>Alcohol_drinks</th>\n",
       "      <th>Screen_Time</th>\n",
       "      <th>Social_Media</th>\n",
       "      <th>Education_yrs</th>\n",
       "      <th>Income_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.749</td>\n",
       "      <td>38.725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.214</td>\n",
       "      <td>68.034</td>\n",
       "      <td>10.686</td>\n",
       "      <td>90.253</td>\n",
       "      <td>128.859</td>\n",
       "      <td>18.203</td>\n",
       "      <td>40.047</td>\n",
       "      <td>46.022</td>\n",
       "      <td>27.775</td>\n",
       "      <td>26.393</td>\n",
       "      <td>17.924</td>\n",
       "      <td>14.043</td>\n",
       "      <td>4.635</td>\n",
       "      <td>101.669</td>\n",
       "      <td>12.066</td>\n",
       "      <td>53.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.977</td>\n",
       "      <td>21.725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.772</td>\n",
       "      <td>47.019</td>\n",
       "      <td>9.261</td>\n",
       "      <td>13.579</td>\n",
       "      <td>127.974</td>\n",
       "      <td>24.378</td>\n",
       "      <td>40.902</td>\n",
       "      <td>45.864</td>\n",
       "      <td>31.934</td>\n",
       "      <td>39.152</td>\n",
       "      <td>15.379</td>\n",
       "      <td>13.300</td>\n",
       "      <td>5.053</td>\n",
       "      <td>123.524</td>\n",
       "      <td>16.200</td>\n",
       "      <td>46.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.518</td>\n",
       "      <td>22.310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.552</td>\n",
       "      <td>49.828</td>\n",
       "      <td>12.050</td>\n",
       "      <td>106.348</td>\n",
       "      <td>145.061</td>\n",
       "      <td>21.738</td>\n",
       "      <td>36.926</td>\n",
       "      <td>31.669</td>\n",
       "      <td>27.323</td>\n",
       "      <td>24.979</td>\n",
       "      <td>30.000</td>\n",
       "      <td>7.269</td>\n",
       "      <td>2.137</td>\n",
       "      <td>77.506</td>\n",
       "      <td>14.809</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.456</td>\n",
       "      <td>57.052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.300</td>\n",
       "      <td>42.785</td>\n",
       "      <td>10.288</td>\n",
       "      <td>189.541</td>\n",
       "      <td>123.524</td>\n",
       "      <td>19.864</td>\n",
       "      <td>70.923</td>\n",
       "      <td>56.874</td>\n",
       "      <td>25.809</td>\n",
       "      <td>24.946</td>\n",
       "      <td>15.551</td>\n",
       "      <td>6.180</td>\n",
       "      <td>5.503</td>\n",
       "      <td>126.785</td>\n",
       "      <td>16.889</td>\n",
       "      <td>73.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.553</td>\n",
       "      <td>38.521</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.632</td>\n",
       "      <td>70.622</td>\n",
       "      <td>16.008</td>\n",
       "      <td>99.384</td>\n",
       "      <td>395.248</td>\n",
       "      <td>14.299</td>\n",
       "      <td>48.087</td>\n",
       "      <td>35.802</td>\n",
       "      <td>21.624</td>\n",
       "      <td>38.411</td>\n",
       "      <td>13.696</td>\n",
       "      <td>4.326</td>\n",
       "      <td>11.011</td>\n",
       "      <td>184.122</td>\n",
       "      <td>17.156</td>\n",
       "      <td>27.678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PHQ9     Age  Sex     BMI     HRV  Sleep_Quality  Physical_Activity  \\\n",
       "0   3.749  38.725  0.0  28.214  68.034         10.686             90.253   \n",
       "1   7.977  21.725  0.0  22.772  47.019          9.261             13.579   \n",
       "2   3.518  22.310  1.0  17.552  49.828         12.050            106.348   \n",
       "3  13.456  57.052  0.0  26.300  42.785         10.288            189.541   \n",
       "4  16.553  38.521  1.0  21.632  70.622         16.008             99.384   \n",
       "\n",
       "   Caffeine_mg  Stress_Level  Rumination  Loneliness  Social_Support  \\\n",
       "0      128.859        18.203      40.047      46.022          27.775   \n",
       "1      127.974        24.378      40.902      45.864          31.934   \n",
       "2      145.061        21.738      36.926      31.669          27.323   \n",
       "3      123.524        19.864      70.923      56.874          25.809   \n",
       "4      395.248        14.299      48.087      35.802          21.624   \n",
       "\n",
       "   Neuroticism  Self_Esteem  Alcohol_drinks  Screen_Time  Social_Media  \\\n",
       "0       26.393       17.924          14.043        4.635       101.669   \n",
       "1       39.152       15.379          13.300        5.053       123.524   \n",
       "2       24.979       30.000           7.269        2.137        77.506   \n",
       "3       24.946       15.551           6.180        5.503       126.785   \n",
       "4       38.411       13.696           4.326       11.011       184.122   \n",
       "\n",
       "   Education_yrs  Income_k  \n",
       "0         12.066    53.378  \n",
       "1         16.200    46.492  \n",
       "2         14.809    10.000  \n",
       "3         16.889    73.317  \n",
       "4         17.156    27.678  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first few rows of behavioral data\n",
    "behavior = helpers.get_behavior()\n",
    "behavior = behavior.astype(float).round(3)\n",
    "behavior.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "behavior-describe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PHQ9</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BMI</th>\n",
       "      <th>HRV</th>\n",
       "      <th>Sleep_Quality</th>\n",
       "      <th>Physical_Activity</th>\n",
       "      <th>Caffeine_mg</th>\n",
       "      <th>Stress_Level</th>\n",
       "      <th>Rumination</th>\n",
       "      <th>Loneliness</th>\n",
       "      <th>Social_Support</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Self_Esteem</th>\n",
       "      <th>Alcohol_drinks</th>\n",
       "      <th>Screen_Time</th>\n",
       "      <th>Social_Media</th>\n",
       "      <th>Education_yrs</th>\n",
       "      <th>Income_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.224925</td>\n",
       "      <td>37.876045</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>26.945810</td>\n",
       "      <td>53.724775</td>\n",
       "      <td>9.944630</td>\n",
       "      <td>129.81592</td>\n",
       "      <td>219.456310</td>\n",
       "      <td>20.067190</td>\n",
       "      <td>44.507715</td>\n",
       "      <td>42.874075</td>\n",
       "      <td>27.848115</td>\n",
       "      <td>27.444445</td>\n",
       "      <td>18.969445</td>\n",
       "      <td>6.261150</td>\n",
       "      <td>7.19959</td>\n",
       "      <td>110.068985</td>\n",
       "      <td>13.953635</td>\n",
       "      <td>49.260200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.549550</td>\n",
       "      <td>12.892744</td>\n",
       "      <td>0.501255</td>\n",
       "      <td>5.327202</td>\n",
       "      <td>13.342101</td>\n",
       "      <td>4.139252</td>\n",
       "      <td>56.14362</td>\n",
       "      <td>113.219054</td>\n",
       "      <td>7.214863</td>\n",
       "      <td>12.307568</td>\n",
       "      <td>11.280076</td>\n",
       "      <td>8.580074</td>\n",
       "      <td>8.927761</td>\n",
       "      <td>6.048969</td>\n",
       "      <td>4.241435</td>\n",
       "      <td>3.02909</td>\n",
       "      <td>49.968209</td>\n",
       "      <td>2.291382</td>\n",
       "      <td>20.864014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.381000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.542000</td>\n",
       "      <td>28.260750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.124500</td>\n",
       "      <td>45.468000</td>\n",
       "      <td>7.020250</td>\n",
       "      <td>88.64500</td>\n",
       "      <td>137.006000</td>\n",
       "      <td>14.985250</td>\n",
       "      <td>36.687500</td>\n",
       "      <td>35.693750</td>\n",
       "      <td>22.100750</td>\n",
       "      <td>22.701250</td>\n",
       "      <td>14.876250</td>\n",
       "      <td>2.649750</td>\n",
       "      <td>5.17425</td>\n",
       "      <td>78.585500</td>\n",
       "      <td>12.352500</td>\n",
       "      <td>34.126750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.008000</td>\n",
       "      <td>38.377000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>26.806000</td>\n",
       "      <td>54.160500</td>\n",
       "      <td>10.021500</td>\n",
       "      <td>132.23750</td>\n",
       "      <td>208.145000</td>\n",
       "      <td>19.648000</td>\n",
       "      <td>44.861500</td>\n",
       "      <td>42.514000</td>\n",
       "      <td>26.755000</td>\n",
       "      <td>27.720500</td>\n",
       "      <td>19.498000</td>\n",
       "      <td>6.292500</td>\n",
       "      <td>7.27700</td>\n",
       "      <td>108.712500</td>\n",
       "      <td>14.006000</td>\n",
       "      <td>47.737000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.724000</td>\n",
       "      <td>46.364000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.881500</td>\n",
       "      <td>62.542500</td>\n",
       "      <td>13.178500</td>\n",
       "      <td>168.26525</td>\n",
       "      <td>300.228500</td>\n",
       "      <td>24.958000</td>\n",
       "      <td>52.379750</td>\n",
       "      <td>50.507250</td>\n",
       "      <td>33.636250</td>\n",
       "      <td>32.674250</td>\n",
       "      <td>23.198750</td>\n",
       "      <td>9.628250</td>\n",
       "      <td>9.29575</td>\n",
       "      <td>146.082250</td>\n",
       "      <td>15.325750</td>\n",
       "      <td>64.079500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.931000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.051000</td>\n",
       "      <td>97.032000</td>\n",
       "      <td>20.765000</td>\n",
       "      <td>257.85200</td>\n",
       "      <td>504.746000</td>\n",
       "      <td>37.512000</td>\n",
       "      <td>80.963000</td>\n",
       "      <td>71.575000</td>\n",
       "      <td>50.664000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>15.920000</td>\n",
       "      <td>15.27100</td>\n",
       "      <td>258.395000</td>\n",
       "      <td>20.521000</td>\n",
       "      <td>107.075000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PHQ9         Age         Sex         BMI         HRV  \\\n",
       "count  200.000000  200.000000  200.000000  200.000000  200.000000   \n",
       "mean     8.224925   37.876045    0.500000   26.945810   53.724775   \n",
       "std      5.549550   12.892744    0.501255    5.327202   13.342101   \n",
       "min      0.000000   18.000000    0.000000   15.000000   10.000000   \n",
       "25%      3.542000   28.260750    0.000000   23.124500   45.468000   \n",
       "50%      8.008000   38.377000    0.500000   26.806000   54.160500   \n",
       "75%     12.724000   46.364000    1.000000   30.881500   62.542500   \n",
       "max     21.931000   70.000000    1.000000   44.051000   97.032000   \n",
       "\n",
       "       Sleep_Quality  Physical_Activity  Caffeine_mg  Stress_Level  \\\n",
       "count     200.000000          200.00000   200.000000    200.000000   \n",
       "mean        9.944630          129.81592   219.456310     20.067190   \n",
       "std         4.139252           56.14362   113.219054      7.214863   \n",
       "min         0.000000            0.00000     0.000000      0.866000   \n",
       "25%         7.020250           88.64500   137.006000     14.985250   \n",
       "50%        10.021500          132.23750   208.145000     19.648000   \n",
       "75%        13.178500          168.26525   300.228500     24.958000   \n",
       "max        20.765000          257.85200   504.746000     37.512000   \n",
       "\n",
       "       Rumination  Loneliness  Social_Support  Neuroticism  Self_Esteem  \\\n",
       "count  200.000000  200.000000      200.000000   200.000000   200.000000   \n",
       "mean    44.507715   42.874075       27.848115    27.444445    18.969445   \n",
       "std     12.307568   11.280076        8.580074     8.927761     6.048969   \n",
       "min     22.000000   20.000000       12.000000     0.000000     4.381000   \n",
       "25%     36.687500   35.693750       22.100750    22.701250    14.876250   \n",
       "50%     44.861500   42.514000       26.755000    27.720500    19.498000   \n",
       "75%     52.379750   50.507250       33.636250    32.674250    23.198750   \n",
       "max     80.963000   71.575000       50.664000    48.000000    30.000000   \n",
       "\n",
       "       Alcohol_drinks  Screen_Time  Social_Media  Education_yrs    Income_k  \n",
       "count      200.000000    200.00000    200.000000     200.000000  200.000000  \n",
       "mean         6.261150      7.19959    110.068985      13.953635   49.260200  \n",
       "std          4.241435      3.02909     49.968209       2.291382   20.864014  \n",
       "min          0.000000      0.00000      0.000000      10.000000   10.000000  \n",
       "25%          2.649750      5.17425     78.585500      12.352500   34.126750  \n",
       "50%          6.292500      7.27700    108.712500      14.006000   47.737000  \n",
       "75%          9.628250      9.29575    146.082250      15.325750   64.079500  \n",
       "max         15.920000     15.27100    258.395000      20.521000  107.075000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics\n",
    "behavior.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "describe-interp",
   "metadata": {},
   "source": [
    "Each row is one subject. The table above shows the mean, standard deviation (std), minimum, and maximum for each variable. The 25%/50%/75% rows are **percentiles** -- for example, the 50% row is the median (the middle value)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "background",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Background and Hypothesis\n",
    "\n",
    "### Depression and the Salience Network\n",
    "\n",
    "Research has consistently linked **salience network** dysfunction to major depressive disorder. The salience network -- anchored by the anterior insula and dorsal anterior cingulate cortex (dACC) -- is responsible for detecting and filtering important stimuli. The salience network helps the brain decide what is important to pay attention to and what to ignore. In depression, this filtering process may be disrupted, leading to excessive focus on negative information. Altered connectivity between insular and medial frontal components of this network may disrupt emotional processing and interoceptive awareness.\n",
    "\n",
    "### Relevant Literature\n",
    "\n",
    "> Insert: Paper on anterior insula role in interoception and emotional awareness\n",
    "\n",
    "> Insert: Paper on salience network dysfunction in depression\n",
    "\n",
    "> <a href=\"https://www.nature.com/articles/s41586-024-07805-2\">Lynch et al 2024:</a>\n",
    "\n",
    "> <a href=\"https://pubmed.ncbi.nlm.nih.gov/32680763/\">Pimontel et al. 2021:</a> Cortical Thickness of the Salience Network and Change in Apathy Following Antidepressant Treatment for Late-Life Depression, American Journal of Geriatric Psychiatry\n",
    "\n",
    "Based on this literature, connectivity between insular and medial frontal regions of the salience network may predict individual differences in depression severity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-reference",
   "metadata": {},
   "source": [
    "### Quick Reference: Functional Connectivity Concepts\n",
    "\n",
    "**Functional connectivity (FC)** measures how correlated the activity is between two brain regions during a resting-state fMRI scan.\n",
    "\n",
    "**Key terms:**\n",
    "- **ROI (Region of Interest)**: A specific brain area. This dataset has 216 ROIs from a standard brain atlas.\n",
    "- **Edge**: A connection between two ROIs. Each edge has a connectivity value per subject. With 216 ROIs, there are 23,220 unique edges.\n",
    "- **Network**: ROIs are grouped into brain networks (e.g., Default Mode, Salience, Subcortical) based on their function.\n",
    "\n",
    "**Interpreting Pearson r** (correlation strength):\n",
    "- |r| < 0.10 -- negligible\n",
    "- |r| around 0.10-0.20 -- small\n",
    "- |r| around 0.20-0.30 -- medium\n",
    "- |r| > 0.30 -- large (rare in neuroimaging)\n",
    "\n",
    "**r-squared** (r x r) tells you the proportion of variance explained. An r of 0.20 means r-squared = 0.04 -- the brain connection explains about 4% of individual differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formulate-hypothesis",
   "metadata": {},
   "source": [
    "### Your Turn: Formulate Your Hypothesis\n",
    "\n",
    "Based on the literature above, write your hypothesis in one sentence. What brain regions do you expect to be connected to PHQ9? In which direction (positive or negative)?\n",
    "\n",
    "> **H1: Connectivity between insular (Ins) and medial frontal (FrMed) regions of the SalVentAttnA network correlates with PHQ9.**\n",
    "\n",
    "This is a focused hypothesis: you are testing only edges connecting SalVentAttnA insula regions with SalVentAttnA frontal medial regions -- a small number of specific connections motivated by the literature.\n",
    "\n",
    "Take a moment to think about *why* you expect this relationship. What does the literature suggest about how salience network disruption might relate to depression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explore-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Explore Your Target Regions\n",
    "\n",
    "Before testing your hypothesis, examine the regions involved and visualize an example edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list-salventattn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What regions are in the SalVentAttnA network?\n",
    "helpers.list_regions('SalVentAttnA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list-networks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of all networks\n",
    "helpers.list_networks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "describe-tip",
   "metadata": {},
   "source": [
    "**Tip:** Use `helpers.describe_regions('SalVentAttnA')` to see decoded names for each region (e.g., what \"Ins\" and \"FrMed\" stand for)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "describe-regions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See decoded region names for the Salience network\n",
    "helpers.describe_regions('SalVentAttnA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-connectome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the overall connectivity structure\n",
    "helpers.plot_connectome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-salventattn-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoomed view of SalVentAttnA within-network connectivity\n",
    "helpers.plot_network_matrix('SalVentAttnA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-edge-header",
   "metadata": {},
   "source": [
    "### Visualize a Single Edge\n",
    "\n",
    "Before diving into analysis, let's see what a brain connectivity scatter plot actually looks like. Here we'll plot the connectivity between two subcortical regions against Age -- this is just to get familiar with the visualization, not to test your hypothesis yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-single-edge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot connectivity between two subcortical regions vs Age\n",
    "# This is just to see what an FC scatter plot looks like\n",
    "helpers.plot_edge('HIP-lh', 'AMY-lh', 'Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toolkit-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Your Analysis Toolkit\n",
    "\n",
    "Before testing your hypothesis, let's learn the analytical tools available to you. Each tool is a legitimate technique that researchers use every day. Understanding these tools will help you make informed decisions when you pre-register your analysis plan in Part 6.\n",
    "\n",
    "All of these tools work with both `plot_edge()` and the mass testing functions (`test_all_edges()`, `test_network_edges()`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cov-header",
   "metadata": {},
   "source": [
    "### 5a. Covariates: Controlling for Confounding Variables\n",
    "\n",
    "A **covariate** is a variable you account for (\"control for\") to see whether a relationship still holds after removing its influence. When you control for a variable, the axes show \"residualized\" values -- what's left of each variable after statistically removing the influence of the covariate.\n",
    "\n",
    "**Why does this matter?** Sometimes two variables look related, but the apparent relationship is actually driven by a third variable. Let's see an example with the behavioral data first, then apply the same logic to brain data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cov-behavior-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is Social_Media use related to Sleep_Quality?\n",
    "helpers.plot_behavior('Social_Media', 'Sleep_Quality')\n",
    "\n",
    "# People who use more screens overall may have both more social media use\n",
    "# AND worse sleep. Let's control for Screen_Time and see what happens:\n",
    "helpers.plot_behavior('Social_Media', 'Sleep_Quality', covariates=['Screen_Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cov-brain-header",
   "metadata": {},
   "source": [
    "Notice how the correlation changes after controlling for Screen_Time. The apparent link between social media and sleep quality was largely driven by overall screen time.\n",
    "\n",
    "The same principle applies to brain data. Let's see how controlling for a behavioral variable changes a brain connectivity relationship:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cov-brain-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does hippocampus-visual cortex connectivity predict PHQ9?\n",
    "helpers.plot_edge('HIP-lh', 'LH_VisCent_ExStr_4', 'PHQ9')\n",
    "\n",
    "# Now control for Stress_Level and see what happens:\n",
    "helpers.plot_edge('HIP-lh', 'LH_VisCent_ExStr_4', 'PHQ9',\n",
    "                  covariates=['Stress_Level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cov-message",
   "metadata": {},
   "source": [
    "Notice how the correlation changed after controlling for Stress_Level. Covariates can **strengthen or weaken** findings. The important thing is to choose your covariates **before** you see your results -- otherwise you might unconsciously pick covariates that make your findings look better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outlier-header",
   "metadata": {},
   "source": [
    "### 5b. Outlier Handling\n",
    "\n",
    "An **outlier** is a data point that is unusually far from the rest. **Z-scores** measure how many standard deviations (SD) a value is from the mean. A z-score of 2 means the value is in roughly the most extreme 5% of data; a z-score of 3 is the most extreme 0.3%.\n",
    "\n",
    "Outliers can have a big impact on correlations. Sometimes a \"significant\" result is driven entirely by a few extreme values. Other times, outliers can obscure a real effect. Let's see both cases.\n",
    "\n",
    "You can add an `exclude_outliers` argument to remove extreme values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outlier-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 1: A \"significant\" result that disappears when outliers are removed\n",
    "print('--- With all data ---')\n",
    "helpers.plot_edge('LH_DorsAttnB_PostC_2', 'LH_LimbicA_TempPole_2', 'PHQ9')\n",
    "\n",
    "print('--- After removing outliers (z > 2) ---')\n",
    "helpers.plot_edge('LH_DorsAttnB_PostC_2', 'LH_LimbicA_TempPole_2', 'PHQ9',\n",
    "                  exclude_outliers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outlier-message",
   "metadata": {},
   "source": [
    "The correlation went from \"significant\" to nowhere near significant. Those few extreme data points were creating the illusion of a relationship.\n",
    "\n",
    "Now let's see the opposite -- outliers *hiding* a real effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outlier-demo-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 2: A real effect that only appears after removing outliers\n",
    "print('--- With all data ---')\n",
    "helpers.plot_edge('RH_VisCent_ExStr_5', 'RH_DorsAttnA_SPL_2', 'PHQ9')\n",
    "\n",
    "print('--- After removing outliers (z > 2) ---')\n",
    "helpers.plot_edge('RH_VisCent_ExStr_5', 'RH_DorsAttnA_SPL_2', 'PHQ9',\n",
    "                  exclude_outliers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outlier-closing",
   "metadata": {},
   "source": [
    "After removing extreme values, a real relationship emerged. Outliers can work both ways -- they can create false positives or hide true effects. That is why your outlier handling strategy should be decided **in advance** as part of your pre-registration, not adjusted after seeing your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subgroup-header",
   "metadata": {},
   "source": [
    "### 5c. Subgroup Analysis\n",
    "\n",
    "Sometimes a relationship looks completely different depending on who you include. Here's a striking example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subgroup-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall relationship: neuroticism vs self-esteem\n",
    "helpers.plot_behavior('Neuroticism', 'Self_Esteem')\n",
    "\n",
    "# Does the relationship differ by sex?\n",
    "helpers.plot_behavior('Neuroticism', 'Self_Esteem', subgroup={'Sex': 0})  # women\n",
    "helpers.plot_behavior('Neuroticism', 'Self_Esteem', subgroup={'Sex': 1})  # men"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subgroup-message",
   "metadata": {},
   "source": [
    "The overall relationship shows almost no correlation, but when you split by sex, you see that women have a *negative* relationship while men have a *positive* one -- they cancel each other out in the full sample. Subgroup analysis can reveal effects hidden by aggregation. But there is an important trade-off: splitting your sample **reduces your sample size and statistical power**. Only analyze subgroups if you have a strong reason from the literature -- not just because it makes your results look better.\n",
    "\n",
    "The `subgroup` argument works with brain data too:\n",
    "```python\n",
    "helpers.plot_edge('LH_SalVentAttnA_Ins_1', 'RH_SalVentAttnA_FrMed_1', 'PHQ9', subgroup={'Sex': 0})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mc-header",
   "metadata": {},
   "source": [
    "### 5d. Multiple Comparisons\n",
    "\n",
    "When you test many edges at once, some will appear \"significant\" just by chance. If you test 100 edges at p < 0.05, you would expect about 5 false positives even if there are no real effects at all.\n",
    "\n",
    "There are two common ways to correct for this:\n",
    "\n",
    "- **Bonferroni correction**: Divide your alpha (0.05) by the number of tests. Very conservative -- it controls the chance of *any* false positive. Simple, but can miss real effects when you have many tests.\n",
    "\n",
    "- **FDR (False Discovery Rate) correction** (Benjamini-Hochberg): Controls the *proportion* of false positives among your significant results. Less conservative, and the standard in neuroimaging research.\n",
    "\n",
    "Let's see this in action with an example unrelated to your hypothesis. We will test all edges within the Limbic network against PHQ9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mc-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all within-Limbic edges vs PHQ9 (NOT your hypothesis -- just a demo)\n",
    "limbic_results = helpers.test_network_edges('Limbic', within=True)\n",
    "n_limbic = len(limbic_results)\n",
    "\n",
    "# How many are \"significant\" without correction?\n",
    "n_uncorrected = (limbic_results['p'] < 0.05).sum()\n",
    "print(f'Tested {n_limbic} within-Limbic edges')\n",
    "print(f'Significant at p < 0.05 (uncorrected): {n_uncorrected}')\n",
    "print(f'Expected by chance alone: {n_limbic * 0.05:.0f}')\n",
    "\n",
    "# Now apply FDR correction\n",
    "limbic_fdr = helpers.test_network_edges('Limbic', within=True, correction='fdr')\n",
    "n_fdr = (limbic_fdr['p_corrected'] < 0.05).sum()\n",
    "print(f'\\nSignificant after FDR correction: {n_fdr}')\n",
    "print(f'\\nMany \"findings\" disappear after proper correction!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mc-closing",
   "metadata": {},
   "source": [
    "This is why multiple comparison correction is essential. Without it, you would report false positives as real findings. In your pre-registration below, we will use **FDR correction** as the default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toolkit-closing",
   "metadata": {},
   "source": [
    "### Key Takeaway\n",
    "\n",
    "You now have a full toolkit: **covariates**, **outlier handling**, and **subgroup analysis**. In the next section, you will formally commit to your analysis choices **before** seeing the results. This is called **pre-registration** -- it is what separates hypothesis-driven science from exploratory analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preregistration-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Pre-Register Your Analysis\n",
    "\n",
    "In real research, scientists often **pre-register** their analysis plan before collecting data. This means writing down exactly what you will test and how -- before you see the results. Pre-registration prevents you from unconsciously adjusting your analysis to get the answer you want.\n",
    "\n",
    "Fill in each section below. Once you have committed to your plan, you will execute it in Part 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preregistration-template",
   "metadata": {},
   "source": [
    "### My Pre-Registration\n",
    "\n",
    "**Hypothesis:** Connectivity between insular (Ins) and medial frontal (FrMed) regions of the SalVentAttnA network correlates with PHQ9.\n",
    "\n",
    "**Edges to test:** [Which specific edges will you test? e.g., \"SalVentAttnA Ins <-> SalVentAttnA FrMed edges\"]\n",
    "\n",
    "**Number of tests:** [How many edges does this include? You will find out when you run the code in Part 8.]\n",
    "\n",
    "**Correction method:** FDR (Benjamini-Hochberg) -- see explanation below\n",
    "\n",
    "**Covariates:** [Which covariates will you control for, if any? Justify your choice based on the literature. Write \"None\" if you will not use covariates.]\n",
    "\n",
    "**Outlier handling:** [Will you exclude outliers? If so, at what z-score threshold? (e.g., 2 or 3) Write \"None\" if you will not exclude outliers.]\n",
    "\n",
    "**Subgroup analysis:** [Will you analyze any subgroups? If so, which? Write \"None\" if you will analyze the full sample.]\n",
    "\n",
    "**Significance threshold:** 0.05 (after FDR correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practice-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Practice -- Testing a Known Effect\n",
    "\n",
    "Before testing your hypothesis, let's practice with a well-established finding.\n",
    "\n",
    "It is well documented in the neuroscience literature that functional connectivity within the **Default Mode Network** decreases with age. This is one of the most replicated findings in resting-state fMRI research. Let's test this in our data to build confidence with the tools before applying them to your hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practice-single-edge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a single Default Mode Network edge vs Age\n",
    "# These two regions are both in the Default Mode Network:\n",
    "#   - LH_DefaultA_PFCm_1 = left medial prefrontal cortex\n",
    "#   - LH_DefaultA_pCunPCC_1 = left precuneus/posterior cingulate\n",
    "helpers.plot_edge('LH_DefaultA_PFCm_1', 'LH_DefaultA_pCunPCC_1', 'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practice-test-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all within-Default Mode edges vs Age with FDR correction\n",
    "dmn_age = helpers.test_network_edges('Default Mode', behavior_col='Age',\n",
    "                                      correction='fdr', within=True)\n",
    "\n",
    "n_sig = (dmn_age['p_corrected'] < 0.05).sum()\n",
    "print(f\"\\nEdges with significant age-related decline (FDR corrected): {n_sig}\")\n",
    "\n",
    "# Show the top findings\n",
    "print(\"\\nTop 10 within-Default Mode edges correlated with Age:\")\n",
    "print(dmn_age.head(10)[['ROI_A', 'ROI_B', 'r', 'p', 'p_corrected']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practice-interp",
   "metadata": {},
   "source": [
    "You should see mostly **negative correlations** -- as age increases, Default Mode Network connectivity decreases. This is one of the most replicated findings in neuroscience.\n",
    "\n",
    "If you see significant results after FDR correction, that confirms the tools are working correctly and the data contains real brain-behavior relationships.\n",
    "\n",
    "Now you are ready to test your own hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Test Your Hypothesis\n",
    "\n",
    "Now execute your pre-registered analysis plan. The code below tests your hypothesis edges -- SalVentAttnA insula regions connected to SalVentAttnA medial frontal regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-salventattn-edges",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Test edges involving the Salience network\n",
    "# We focus on Salience because our hypothesis is about SalVentAttnA connectivity\n",
    "all_results = helpers.test_network_edges('Salience')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filter-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Filter to your specific hypothesis edges\n",
    "# Keep only rows where one region is SalVentAttnA Ins and the other is SalVentAttnA FrMed\n",
    "hyp_mask = (\n",
    "    (all_results['ROI_A'].str.contains('SalVentAttnA') & all_results['ROI_A'].str.contains('Ins') &\n",
    "     all_results['ROI_B'].str.contains('SalVentAttnA') & all_results['ROI_B'].str.contains('FrMed')) |\n",
    "    (all_results['ROI_B'].str.contains('SalVentAttnA') & all_results['ROI_B'].str.contains('Ins') &\n",
    "     all_results['ROI_A'].str.contains('SalVentAttnA') & all_results['ROI_A'].str.contains('FrMed'))\n",
    ")\n",
    "hyp_results = all_results[hyp_mask].reset_index(drop=True)\n",
    "\n",
    "n_hyp_tests = len(hyp_results)\n",
    "print(f\"SalVentAttnA Ins <-> FrMed edges to test: {n_hyp_tests}\")\n",
    "print(f\"\\nAll results (sorted by p-value):\")\n",
    "hyp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preregistered-choices-header",
   "metadata": {},
   "source": [
    "### Apply Your Pre-Registered Choices\n",
    "\n",
    "Modify the code below based on what you wrote in your pre-registration (Part 6). If you chose not to use covariates, outliers, or subgroups, leave them set to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apply-preregistered",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Apply your pre-registered analysis choices\n",
    "# Edit these variables based on what you wrote in your pre-registration:\n",
    "\n",
    "covariates = None              # e.g., ['Age', 'Sex'] or None for no covariates\n",
    "outlier_threshold = None       # e.g., 2 or 3, or None for no outlier removal\n",
    "subgroup = None                # e.g., {'Sex': 0} or None for full sample\n",
    "\n",
    "# Re-test with your pre-registered choices (only if you specified any)\n",
    "if covariates is not None or outlier_threshold is not None or subgroup is not None:\n",
    "    all_results = helpers.test_network_edges('Salience',\n",
    "                                              covariates=covariates,\n",
    "                                              exclude_outliers=outlier_threshold,\n",
    "                                              subgroup=subgroup)\n",
    "\n",
    "    # Re-filter to hypothesis edges (recompute the mask for the new results)\n",
    "    hyp_mask = (\n",
    "        (all_results['ROI_A'].str.contains('SalVentAttnA') & all_results['ROI_A'].str.contains('Ins') &\n",
    "         all_results['ROI_B'].str.contains('SalVentAttnA') & all_results['ROI_B'].str.contains('FrMed')) |\n",
    "        (all_results['ROI_B'].str.contains('SalVentAttnA') & all_results['ROI_B'].str.contains('Ins') &\n",
    "         all_results['ROI_A'].str.contains('SalVentAttnA') & all_results['ROI_A'].str.contains('FrMed'))\n",
    "    )\n",
    "    hyp_results = all_results[hyp_mask].reset_index(drop=True)\n",
    "    n_hyp_tests = len(hyp_results)\n",
    "    print(f\"\\nRe-filtered to {n_hyp_tests} hypothesis edges with your pre-registered choices.\")\n",
    "    print(hyp_results[['ROI_A', 'ROI_B', 'r', 'p']].to_string())\n",
    "else:\n",
    "    print(\"No covariates, outlier removal, or subgroup specified.\")\n",
    "    print(\"Using the results from Step 2 above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correction-header",
   "metadata": {},
   "source": [
    "### Apply Multiple Comparison Correction\n",
    "\n",
    "Because you are testing multiple edges, you need to correct for multiple comparisons. There are two common approaches:\n",
    "\n",
    "- **Bonferroni correction**: Divides your alpha (0.05) by the number of tests. Very conservative -- it controls the probability of even one false positive. Simple but can miss real effects.\n",
    "\n",
    "- **FDR (False Discovery Rate) correction**: Controls the *proportion* of false positives among your significant results. Less conservative than Bonferroni, and widely used in neuroimaging research.\n",
    "\n",
    "We will use **FDR correction** (Benjamini-Hochberg method), which is the standard approach in neuroimaging and is what the exploratory group used as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bonferroni",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# Apply FDR (Benjamini-Hochberg) correction\n",
    "reject, p_corrected, _, _ = multipletests(hyp_results['p'], alpha=alpha, method='fdr_bh')\n",
    "hyp_results['p_corrected'] = p_corrected\n",
    "hyp_results['significant_fdr'] = reject\n",
    "\n",
    "# For reference, also compute Bonferroni threshold\n",
    "bonferroni_threshold = alpha / n_hyp_tests\n",
    "\n",
    "n_significant = hyp_results['significant_fdr'].sum()\n",
    "\n",
    "print('=' * 60)\n",
    "print('MULTIPLE COMPARISON CORRECTION')\n",
    "print('=' * 60)\n",
    "print(f'Number of tests: {n_hyp_tests}')\n",
    "print(f'Method: FDR (Benjamini-Hochberg)')\n",
    "print(f'For reference -- Bonferroni threshold would be: {bonferroni_threshold:.6f}')\n",
    "print(f'\\nSignificant after FDR correction: {n_significant}')\n",
    "\n",
    "if n_significant > 0:\n",
    "    print(f'\\nSignificant edges:')\n",
    "    sig = hyp_results[hyp_results['significant_fdr']]\n",
    "    for _, row in sig.iterrows():\n",
    "        print(f\"  {row['ROI_A']} <-> {row['ROI_B']}: r={row['r']:.3f}, p={row['p']:.2e}, p_fdr={row['p_corrected']:.2e}\")\n",
    "else:\n",
    "    print('\\nNo edges survived FDR correction.')\n",
    "    print('Most promising edge:')\n",
    "    top = hyp_results.iloc[0]\n",
    "    print(f\"  {top['ROI_A']} <-> {top['ROI_B']}: r={top['r']:.3f}, p={top['p']:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the top hypothesis-driven findings\n",
    "def _short_name(roi):\n",
    "    \"\"\"Extract readable short name from ROI label.\"\"\"\n",
    "    if '-' in roi:  # Subcortical (e.g., NAc-rh)\n",
    "        return roi\n",
    "    parts = roi.split('_')\n",
    "    if len(parts) >= 4:\n",
    "        return '_'.join(parts[1:-1])  # e.g. SalVentAttnA_Ins\n",
    "    return roi\n",
    "\n",
    "if n_significant > 0:\n",
    "    sig_edges = hyp_results[hyp_results['significant_fdr']]\n",
    "    n_plots = min(len(sig_edges), 3)\n",
    "    fig, axes = plt.subplots(1, n_plots, figsize=(5*n_plots, 4))\n",
    "    if n_plots == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for idx, (_, row) in enumerate(sig_edges.head(n_plots).iterrows()):\n",
    "        edge_vals = helpers.get_edge(row['ROI_A'], row['ROI_B'])\n",
    "        outcome = behavior['PHQ9'].values\n",
    "        r_val, p_val = pearsonr(edge_vals, outcome)\n",
    "\n",
    "        axes[idx].scatter(edge_vals, outcome, alpha=0.5, color='steelblue')\n",
    "        z = np.polyfit(edge_vals, outcome, 1)\n",
    "        x_line = np.linspace(edge_vals.min(), edge_vals.max(), 100)\n",
    "        axes[idx].plot(x_line, np.polyval(z, x_line), color='coral', linewidth=2)\n",
    "        axes[idx].set_xlabel('Functional Connectivity')\n",
    "        axes[idx].set_ylabel('PHQ9')\n",
    "\n",
    "        short_a = _short_name(row['ROI_A'])\n",
    "        short_b = _short_name(row['ROI_B'])\n",
    "        axes[idx].set_title(f'{short_a} <-> {short_b}\\nr = {r_val:.3f}, p = {p_val:.2e}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    top = hyp_results.iloc[0]\n",
    "    helpers.plot_edge(top['ROI_A'], top['ROI_B'], 'PHQ9')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "glass-brain-header",
   "metadata": {},
   "source": [
    "### Visualize Results on the Brain\n",
    "\n",
    "Let's see where your significant edges are located in 3D brain space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "glass-brain-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot significant edges on a glass brain\n",
    "helpers.plot_glass_brain(hyp_results, p_threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p-value-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P-value visualization for all hypothesis tests\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "colors = ['mediumseagreen' if sig else 'gray' for sig in hyp_results['significant_fdr']]\n",
    "plt.scatter(range(len(hyp_results)), hyp_results['p'], c=colors, s=60)\n",
    "plt.axhline(bonferroni_threshold, color='coral', linestyle='--', linewidth=1,\n",
    "            label=f'Bonferroni threshold (p={bonferroni_threshold:.2e})')\n",
    "plt.axhline(0.05, color='orange', linestyle='--', linewidth=1,\n",
    "            label='Uncorrected alpha = 0.05')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Edge (ranked by p-value)')\n",
    "plt.ylabel('P-value (log scale)')\n",
    "plt.title(f'P-values for {n_hyp_tests} SalVentAttnA Insula-FrMed Tests')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Green dots = significant after FDR correction')\n",
    "print(f'Note: FDR correction uses a step-up procedure, not a single threshold line.')\n",
    "print(f'The Bonferroni line is shown for reference only.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presentation-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Prepare Your Presentation\n",
    "\n",
    "For next class, prepare a brief presentation (5-7 minutes) covering:\n",
    "\n",
    "1. **Your hypothesis** -- What did you predict and why?\n",
    "2. **Your pre-registered methods** -- Which edges did you test? What correction, covariates, and outlier threshold did you use?\n",
    "3. **Your results** -- Report ALL tests (not just significant ones). Show visualizations.\n",
    "4. **Why you believe your findings** -- What makes you confident? Do the brain regions make sense?\n",
    "5. **How would you convince a skeptic?** -- What evidence would you point to?\n",
    "\n",
    "**Important**: Be honest about null results! Rigorous science means reporting what you found, not just what you hoped to find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-figures",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your key figures for your presentation\n",
    "# Re-plot your strongest finding and save it\n",
    "if n_significant > 0:\n",
    "    top = hyp_results[hyp_results['significant_fdr']].iloc[0]\n",
    "    helpers.plot_edge(top['ROI_A'], top['ROI_B'], 'PHQ9',\n",
    "                      covariates=covariates,\n",
    "                      exclude_outliers=outlier_threshold,\n",
    "                      subgroup=subgroup)\n",
    "    plt.savefig('my_finding.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"Figure saved as 'my_finding.png'\")\n",
    "    print(\"Download this file for your presentation.\")\n",
    "else:\n",
    "    top = hyp_results.iloc[0]\n",
    "    helpers.plot_edge(top['ROI_A'], top['ROI_B'], 'PHQ9',\n",
    "                      covariates=covariates,\n",
    "                      exclude_outliers=outlier_threshold,\n",
    "                      subgroup=subgroup)\n",
    "    plt.savefig('my_finding.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"Figure saved as 'my_finding.png'\")\n",
    "    print(\"Even null results are worth presenting!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "day2-divider",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# DAY 2 STARTS HERE\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reconnect-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 10: Reconnect and Reflect\n",
    "\n",
    "If your Colab runtime disconnected since Day 1, run the cell below to reload everything. If your runtime is still active, you can skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "day2-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 2 Setup: Re-run if your runtime disconnected\n",
    "import subprocess, sys\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'nilearn', '-q'])\n",
    "\n",
    "import os, urllib.request\n",
    "base_url = 'https://raw.githubusercontent.com/cmahlen/python-stats-demo/main/'\n",
    "files_needed = [\n",
    "    'lab_helpers.py', 'atlas_labels.txt', 'data/roi_mni_coords.npy',\n",
    "    'data/depression_discovery.npz', 'data/depression_validation.npz',\n",
    "]\n",
    "os.makedirs('data', exist_ok=True)\n",
    "for f in files_needed:\n",
    "    if not os.path.exists(f):\n",
    "        urllib.request.urlretrieve(base_url + f, f)\n",
    "\n",
    "import lab_helpers as helpers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "helpers.load_dataset('depression', 'discovery')\n",
    "behavior = helpers.get_behavior()\n",
    "\n",
    "# Re-run your hypothesis test\n",
    "all_results = helpers.test_network_edges('Salience')\n",
    "hyp_mask = (\n",
    "    (all_results['ROI_A'].str.contains('SalVentAttnA') & all_results['ROI_A'].str.contains('Ins') &\n",
    "     all_results['ROI_B'].str.contains('SalVentAttnA') & all_results['ROI_B'].str.contains('FrMed')) |\n",
    "    (all_results['ROI_B'].str.contains('SalVentAttnA') & all_results['ROI_B'].str.contains('Ins') &\n",
    "     all_results['ROI_A'].str.contains('SalVentAttnA') & all_results['ROI_A'].str.contains('FrMed'))\n",
    ")\n",
    "hyp_results = all_results[hyp_mask].reset_index(drop=True)\n",
    "n_hyp_tests = len(hyp_results)\n",
    "\n",
    "# Re-apply your pre-registered choices\n",
    "covariates = None              # <-- Match what you used on Day 1\n",
    "outlier_threshold = None       # <-- Match what you used on Day 1\n",
    "subgroup = None                # <-- Match what you used on Day 1\n",
    "\n",
    "if covariates is not None or outlier_threshold is not None or subgroup is not None:\n",
    "    all_results = helpers.test_network_edges('Salience',\n",
    "                                              covariates=covariates,\n",
    "                                              exclude_outliers=outlier_threshold,\n",
    "                                              subgroup=subgroup)\n",
    "    hyp_mask = (\n",
    "        (all_results['ROI_A'].str.contains('SalVentAttnA') & all_results['ROI_A'].str.contains('Ins') &\n",
    "         all_results['ROI_B'].str.contains('SalVentAttnA') & all_results['ROI_B'].str.contains('FrMed')) |\n",
    "        (all_results['ROI_B'].str.contains('SalVentAttnA') & all_results['ROI_B'].str.contains('Ins') &\n",
    "         all_results['ROI_A'].str.contains('SalVentAttnA') & all_results['ROI_A'].str.contains('FrMed'))\n",
    "    )\n",
    "    hyp_results = all_results[hyp_mask].reset_index(drop=True)\n",
    "    n_hyp_tests = len(hyp_results)\n",
    "\n",
    "alpha = 0.05\n",
    "reject, p_corrected, _, _ = multipletests(hyp_results['p'], alpha=alpha, method='fdr_bh')\n",
    "hyp_results['p_corrected'] = p_corrected\n",
    "hyp_results['significant_fdr'] = reject\n",
    "bonferroni_threshold = alpha / n_hyp_tests\n",
    "n_significant = hyp_results['significant_fdr'].sum()\n",
    "\n",
    "def _short_name(roi):\n",
    "    \"\"\"Extract readable short name from ROI label.\"\"\"\n",
    "    if '-' in roi:\n",
    "        return roi\n",
    "    parts = roi.split('_')\n",
    "    if len(parts) >= 4:\n",
    "        return '_'.join(parts[1:-1])\n",
    "    return roi\n",
    "\n",
    "print(f\"\\nReloaded! {n_significant} significant edges (FDR corrected)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection",
   "metadata": {},
   "source": [
    "### Reflection Questions\n",
    "\n",
    "Before we test your findings in the validation data, think about these questions:\n",
    "\n",
    "1. **How confident are you that your findings will replicate?**\n",
    "   - What would make you more or less confident?\n",
    "\n",
    "2. **What could go wrong?**\n",
    "   - Even with Bonferroni correction, could your results still be false positives?\n",
    "\n",
    "3. **How is your approach different from the exploratory group's?**\n",
    "   - How many tests did you run compared to them?\n",
    "   - Did you choose your analysis plan before or after seeing the results?\n",
    "\n",
    "4. **Effect sizes**\n",
    "   - How strong were the correlations you found?\n",
    "   - Are these practically meaningful for understanding depression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 11: Validation\n",
    "\n",
    "### Test your findings in the independent validation set\n",
    "\n",
    "True effects should replicate in new data. You will now re-run your **exact pre-registered analysis** on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the validation dataset\n",
    "helpers.load_dataset('depression', 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation-test-intro",
   "metadata": {},
   "source": [
    "The cell below tests each of your hypothesis edges in the validation dataset and compares the results to your discovery findings. An edge \"replicates\" if it is significant in the same direction in both datasets. You do not need to understand every line of code -- just run the cell and read the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Test ALL hypothesis edges in validation using the SAME analysis choices\n",
    "val_behavior = helpers.get_behavior()\n",
    "val_outcome = val_behavior['PHQ9'].values\n",
    "\n",
    "validation_results = []\n",
    "for _, row in hyp_results.iterrows():\n",
    "    edge_vals = helpers.get_edge(row['ROI_A'], row['ROI_B'])\n",
    "    r_val, p_val = pearsonr(edge_vals, val_outcome)\n",
    "\n",
    "    sig_disc = row['significant_fdr']\n",
    "    # Check both significance AND direction (sign of r must match)\n",
    "    same_direction = (r_val * row['r']) > 0\n",
    "    if sig_disc:\n",
    "        if p_val < 0.05 and same_direction:\n",
    "            replicated = 'YES'\n",
    "        elif p_val < 0.05 and not same_direction:\n",
    "            replicated = 'FLIPPED'\n",
    "        else:\n",
    "            replicated = 'NO'\n",
    "    else:\n",
    "        replicated = 'N/A'\n",
    "\n",
    "    validation_results.append({\n",
    "        'ROI_A': row['ROI_A'],\n",
    "        'ROI_B': row['ROI_B'],\n",
    "        'Disc_r': row['r'],\n",
    "        'Disc_p': row['p'],\n",
    "        'Sig_Disc': sig_disc,\n",
    "        'Val_r': r_val,\n",
    "        'Val_p': p_val,\n",
    "        'Replicated': replicated,\n",
    "    })\n",
    "\n",
    "val_df = pd.DataFrame(validation_results)\n",
    "\n",
    "print('=' * 80)\n",
    "print('VALIDATION RESULTS: SalVentAttnA Insula-FrMed Edges')\n",
    "print('=' * 80)\n",
    "print(f'Validation uses uncorrected p < 0.05 + same direction as replication criterion\\n')\n",
    "\n",
    "display_df = val_df[['ROI_A', 'ROI_B', 'Disc_r', 'Disc_p', 'Sig_Disc', 'Val_r', 'Val_p', 'Replicated']]\n",
    "display_df.index = range(1, len(display_df) + 1)\n",
    "print(display_df.to_string())\n",
    "\n",
    "if n_significant > 0:\n",
    "    n_rep = (val_df['Replicated'] == 'YES').sum()\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f'REPLICATION: {n_rep}/{n_significant} significant findings replicated')\n",
    "    print(f\"{'=' * 80}\")\n",
    "\n",
    "n_flipped = (val_df['Replicated'] == 'FLIPPED').sum()\n",
    "if n_flipped > 0:\n",
    "    print(f'WARNING: {n_flipped} finding(s) were significant but in the OPPOSITE direction!')\n",
    "    print('A flipped direction means the effect is not replicating -- it is noise.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation-viz-intro",
   "metadata": {},
   "source": [
    "The cell below creates side-by-side scatter plots comparing your discovery and validation results. The left plot shows the discovery set; the right plot shows the validation set. If the finding replicated, both plots should show a similar pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side visualization for significant finding(s)\n",
    "if n_significant > 0:\n",
    "    sig_rows = val_df[val_df['Sig_Disc'] == True]\n",
    "\n",
    "    for _, row in sig_rows.iterrows():\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "        # Discovery\n",
    "        helpers.load_dataset('depression', 'discovery')\n",
    "        disc_edge = helpers.get_edge(row['ROI_A'], row['ROI_B'])\n",
    "        disc_out = helpers.get_behavior()['PHQ9'].values\n",
    "        r_d, p_d = pearsonr(disc_edge, disc_out)\n",
    "\n",
    "        axes[0].scatter(disc_edge, disc_out, alpha=0.5, color='steelblue')\n",
    "        z = np.polyfit(disc_edge, disc_out, 1)\n",
    "        x_line = np.linspace(disc_edge.min(), disc_edge.max(), 100)\n",
    "        axes[0].plot(x_line, np.polyval(z, x_line), color='coral', linewidth=2)\n",
    "        axes[0].set_xlabel('Functional Connectivity')\n",
    "        axes[0].set_ylabel('PHQ9')\n",
    "        axes[0].set_title(f'Discovery Set\\nr = {r_d:.3f}, p = {p_d:.2e}')\n",
    "\n",
    "        # Validation\n",
    "        helpers.load_dataset('depression', 'validation')\n",
    "        val_edge = helpers.get_edge(row['ROI_A'], row['ROI_B'])\n",
    "        val_out = helpers.get_behavior()['PHQ9'].values\n",
    "        r_v, p_v = pearsonr(val_edge, val_out)\n",
    "\n",
    "        axes[1].scatter(val_edge, val_out, alpha=0.5, color='mediumseagreen')\n",
    "        z = np.polyfit(val_edge, val_out, 1)\n",
    "        x_line = np.linspace(val_edge.min(), val_edge.max(), 100)\n",
    "        axes[1].plot(x_line, np.polyval(z, x_line), color='coral', linewidth=2)\n",
    "        axes[1].set_xlabel('Functional Connectivity')\n",
    "        axes[1].set_ylabel('PHQ9')\n",
    "        axes[1].set_title(f'Validation Set\\nr = {r_v:.3f}, p = {p_v:.2e}')\n",
    "\n",
    "        short_a = _short_name(row['ROI_A'])\n",
    "        short_b = _short_name(row['ROI_B'])\n",
    "        fig.suptitle(f'{short_a} <-> {short_b}: Discovery vs Validation', fontsize=13)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        if row['Replicated'] == 'YES':\n",
    "            print(f'REPLICATED in validation set!')\n",
    "        else:\n",
    "            print(f'Did not replicate in validation set.')\n",
    "        print()\n",
    "else:\n",
    "    print('No significant findings to visualize.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "your-turn-nonsig",
   "metadata": {},
   "source": [
    "### Your Turn: Test a Non-Significant Edge in Validation\n",
    "\n",
    "Pick one edge from your hypothesis set that was NOT significant in discovery. Does it look any different in validation? This helps build intuition about what \"noise\" looks like.\n",
    "\n",
    "<details>\n",
    "<summary>Hint: Example code</summary>\n",
    "\n",
    "```python\n",
    "# Pick the last (least significant) edge from your hypothesis results\n",
    "nonsig = hyp_results.iloc[-1]\n",
    "helpers.plot_edge(nonsig['ROI_A'], nonsig['ROI_B'], 'PHQ9')\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "your-turn-nonsig-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Turn: test a non-significant edge here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
