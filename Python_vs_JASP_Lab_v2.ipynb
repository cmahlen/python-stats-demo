{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Why Python? A Hands-On Comparison with JASP\n",
    "\n",
    "You just learned how to run statistical tests in JASP. Now let's do the **exact same tests** in Python and see what we gain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "why-python",
   "metadata": {},
   "source": [
    "## Why bother with code when JASP exists?\n",
    "\n",
    "JASP is excellent for learning statistical concepts and running quick analyses. Python offers additional capabilities that become valuable as your research grows:\n",
    "\n",
    "| | JASP (GUI) | Python (Code) |\n",
    "|---|---|---|\n",
    "| **Reproducibility** | Need to remember which buttons you clicked | Save code, run again anytime — same result guaranteed |\n",
    "| **Automation** | Analyze 50 brain regions? Click 50 times | Write a loop — done in seconds |\n",
    "| **Flexibility** | Limited to built-in options | Create any analysis you can describe |\n",
    "| **Transparency** | Results appear; steps are hidden | You control (and can inspect) each step |\n",
    "| **Sharing** | Colleague needs JASP installed | Share a .py file or notebook, anyone can run it|\n",
    "| **Scale** | Great for one dataset at a time | Process thousands of files overnight |\n",
    "\n",
    "**Transferable skills:** Learning Python for statistics opens doors to machine learning, neuroimaging analysis, bioinformatics, finance, web development, and more. The syntax you learn today applies across all these fields.\n",
    "\n",
    "**Bottom line:** JASP is great for learning concepts and quick checks. Python gives you power and flexibility for real research.\n",
    "\n",
    "Let's prove it. We'll replicate everything you just did in JASP — and then go further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Setup and Loading Data\n",
    "\n",
    "First, let's load the Python libraries we need. Think of libraries as toolboxes — each one gives us specific capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we'll use throughout this lab\n",
    "# Each line loads a different \"toolbox\" of functions\n",
    "\n",
    "import pandas as pd              # pandas: for loading and working with data tables\n",
    "import numpy as np               # numpy: for numerical calculations\n",
    "import matplotlib.pyplot as plt  # matplotlib: for creating basic plots\n",
    "import seaborn as sns            # seaborn: for prettier statistical plots\n",
    "import scipy.stats as stats      # scipy.stats: for statistical tests\n",
    "\n",
    "# --- Colab Setup: Download data files from GitHub ---\n",
    "# This cell automatically downloads the data files if running in Google Colab\n",
    "import os\n",
    "if 'google.colab' in str(get_ipython()) or not os.path.exists('class_data_undergrad.xlsx'):\n",
    "    import urllib.request\n",
    "    base_url = 'https://raw.githubusercontent.com/cmahlen/python-stats-demo/main/'\n",
    "    files = ['class_data_undergrad.xlsx', 'ttest_data.xlsx', 'class_data_longitudinal.xlsx']\n",
    "    for f in files:\n",
    "        if not os.path.exists(f):\n",
    "            print(f\"Downloading {f}...\")\n",
    "            urllib.request.urlretrieve(base_url + f, f)\n",
    "    print(\"Data files ready!\")\n",
    "else:\n",
    "    print(\"Using local data files\")\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-context",
   "metadata": {},
   "source": [
    "### The Study\n",
    "\n",
    "A pharmacology experiment examining how dopaminergic drugs affect locomotor activity in rodents.\n",
    "\n",
    "**Dependent Variable**: Number of squares entered in an open-field test (measure of locomotion)\n",
    "\n",
    "**Independent Variables** (8 drug treatment groups):\n",
    "- **Control**: No drug (baseline)\n",
    "- **Amph**: Amphetamine (dopamine releaser — increases locomotion)\n",
    "- **Res only**: Reserpine (depletes dopamine — decreases locomotion)\n",
    "- **Res+Amph**: Can amphetamine overcome reserpine's effects?\n",
    "- **Res+MT**: Reserpine + alpha-methyltyrosine (blocks dopamine synthesis)\n",
    "- **Res+MT+Amph**: Triple combination\n",
    "- **Res+MT+DOPA**: L-DOPA (dopamine precursor) to restore function?\n",
    "- **Res+MT+Amph+DOPA**: Maximum restoration attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-anova-header",
   "metadata": {},
   "source": [
    "### Loading Data: The Peek-Then-Use Pattern\n",
    "\n",
    "**Good habit:** Always look at your data before analyzing it! This helps you catch problems early.\n",
    "\n",
    "We use `pd.read_excel()` to load Excel files. The `pd.` part means \"use the pandas library.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-anova-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ANOVA dataset from an Excel file\n",
    "# pd.read_excel() reads the file and stores it in a variable called anova_df\n",
    "# \"df\" is short for \"DataFrame\" — pandas' name for a data table\n",
    "\n",
    "anova_df = pd.read_excel('class_data_undergrad.xlsx')\n",
    "\n",
    "# .head() shows the first 5 rows — a quick peek at your data\n",
    "# This is your first sanity check: do the columns look right?\n",
    "anova_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082a38c6-c25b-4b99-b194-56dc88474db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also look at the last five rows with .tail()\n",
    "anova_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More quality checks — always do these after loading data!\n",
    "\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# len() counts how many rows\n",
    "print(f\"Number of rows: {len(anova_df)}\")\n",
    "\n",
    "# .columns gives us the column names\n",
    "print(f\"Column names: {list(anova_df.columns)}\")\n",
    "\n",
    "# .isna().sum().sum() counts ALL missing values in the entire dataset\n",
    "print(f\"Missing values: {anova_df.isna().sum().sum()}\")\n",
    "\n",
    "# .unique() shows all the different values in a column\n",
    "print(f\"Groups in the data: {anova_df['Group'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-viz-intro",
   "metadata": {},
   "source": [
    "### Visualize Before Analyzing!\n",
    "\n",
    "**Good habit:** Always plot your data before running statistics. Visualizations help you:\n",
    "- Spot outliers or data entry errors\n",
    "- See the pattern before confirming it with numbers\n",
    "- Choose the right statistical test\n",
    "\n",
    "We'll use a **swarm plot** which shows every individual data point. This is better than a box plot because you see the *actual data*, not just a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a swarm plot showing every data point\n",
    "# sns.swarmplot() is from seaborn — it plots each observation as a dot\n",
    "\n",
    "plt.figure(figsize=(12, 5))  # figsize sets the width and height in inches\n",
    "\n",
    "sns.swarmplot(data=anova_df,           # which dataset to use\n",
    "              x='Group',                # what goes on the x-axis\n",
    "              y='Squares entered',      # what goes on the y-axis\n",
    "              color='steelblue',        # color of the dots (try 'red', 'green', etc.!)\n",
    "              size=6)                   # size of each dot (try 4, 8, 10!)\n",
    "\n",
    "# Try experimenting with rotation= to see what it does. \n",
    "plt.xticks(rotation=45, ha='right')  # rotate x labels so they don't overlap\n",
    "plt.title('Locomotor Activity by Treatment Group')\n",
    "plt.ylabel('Squares Entered')\n",
    "plt.xlabel('Treatment Group')\n",
    "plt.tight_layout()  # prevents labels from getting cut off\n",
    "plt.show()\n",
    "\n",
    "print(\"What patterns do you notice? Which groups look different from Control?\")\n",
    "print(\"\\nTry changing the color to 'coral' or 'forestgreen' and re-run the cell!\")\n",
    "print(\"\\nYou might notice there is a warning telling you to use stripplot.\")\n",
    "print(\"\\nTry it! Replace swarmplot with stripplot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7560f84-faba-4e18-8269-4bf2044388e2",
   "metadata": {},
   "source": [
    "You can use virtually infinitely many colors here. For just some, check out \n",
    "\n",
    "https://matplotlib.org/stable/gallery/color/named_colors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descriptives",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate descriptive statistics by group\n",
    "# This is what JASP calls \"Descriptives\"\n",
    "\n",
    "# .groupby('Group') splits the data by treatment group\n",
    "# ['Squares entered'] selects just that column\n",
    "# .agg() calculates multiple statistics at once\n",
    "\n",
    "descriptives = anova_df.groupby('Group')['Squares entered'].agg(['count', 'mean', 'std'])\n",
    "\n",
    "# Rename columns to be clearer\n",
    "descriptives.columns = ['N', 'Mean', 'SD']\n",
    "\n",
    "# Round to 2 decimal places for readability\n",
    "descriptives = descriptives.round(2)\n",
    "\n",
    "# Reorder groups logically (not alphabetically)\n",
    "group_order = ['Control', 'Amph', 'Res only', 'Res+Amph', 'Res+MT', 'Res+MT+Amph', 'Res+MT+DOPA', 'Res+MT+Amph+DOPA']\n",
    "descriptives = descriptives.reindex(group_order)\n",
    "\n",
    "print(\"Descriptive Statistics by Treatment Group\")\n",
    "print(\"=\" * 50)\n",
    "print(descriptives.to_string())\n",
    "print(\"\\nCompare with your JASP output!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ttest-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: T-Tests\n",
    "\n",
    "Now let's load a different dataset for t-tests. This one compares a \"New\" treatment to an \"Old\" treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-ttest-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the t-test data\n",
    "# This file has two columns: 'New' and 'Old'\n",
    "\n",
    "ttest_df = pd.read_excel('ttest_data.xlsx')\n",
    "\n",
    "# Always peek at your data first!\n",
    "print(\"First few rows:\")\n",
    "print(ttest_df.head())\n",
    "\n",
    "print(f\"\\nNumber of rows: {len(ttest_df)}\")\n",
    "print(f\"Columns: {list(ttest_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-ttest-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the two groups as separate arrays\n",
    "# .dropna() removes any missing values (NaN)\n",
    "# .values converts from pandas Series to numpy array\n",
    "\n",
    "new_data = ttest_df['New'].dropna().values\n",
    "old_data = ttest_df['Old'].dropna().values\n",
    "\n",
    "# Check that we got the data\n",
    "print(f\"New group: n={len(new_data)}, mean={new_data.mean():.2f}, SD={new_data.std(ddof=1):.2f}\")\n",
    "print(f\"Old group: n={len(old_data)}, mean={old_data.mean():.2f}, SD={old_data.std(ddof=1):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-before-ttest",
   "metadata": {},
   "source": [
    "### Visualize Before Testing\n",
    "\n",
    "Before running any statistical test, we should look at the data. Let's create a histogram to see the distribution of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "histogram-ttest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create overlapping histograms to compare distributions\n",
    "# plt.hist() creates a histogram\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Plot both groups on the same axes\n",
    "# alpha controls transparency (0=invisible, 1=solid) — try different values!\n",
    "# bins controls how many bars — try 5, 10, 15, 20!\n",
    "plt.hist(new_data, bins=8, alpha=0.6, label='New', color='steelblue', edgecolor='black')\n",
    "plt.hist(old_data, bins=8, alpha=0.6, label='Old', color='coral', edgecolor='black')\n",
    "\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Comparing New vs Old Treatment Groups')\n",
    "plt.legend()  # shows which color is which group\n",
    "plt.show()\n",
    "\n",
    "print(\"Try changing bins=8 to bins=5 or bins=15 and see how the plot changes!\")\n",
    "print(\"Try changing alpha=0.6 to alpha=0.3 or alpha=0.9!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-ttest-intro",
   "metadata": {},
   "source": [
    "### Independent Samples T-Test\n",
    "\n",
    "**Question**: Is there a difference between the New and Old groups?\n",
    "\n",
    "In JASP: T-Tests → Independent Samples T-Test → drag variables → click options...\n",
    "\n",
    "In Python: One line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-ttest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run an independent samples t-test\n",
    "# stats.ttest_ind() compares two independent groups\n",
    "# It returns two values: the t-statistic and the p-value\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(new_data, old_data)\n",
    "\n",
    "# Print the results\n",
    "print(\"INDEPENDENT SAMPLES T-TEST\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"New group mean: {new_data.mean():.2f} (n={len(new_data)})\")\n",
    "print(f\"Old group mean: {old_data.mean():.2f} (n={len(old_data)})\")\n",
    "print(f\"\\nt = {t_stat:.3f}\")\n",
    "print(f\"p = {p_value:.4f}\")\n",
    "\n",
    "# Interpret the result\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nSignificant at alpha = 0.05? Yes\")\n",
    "else:\n",
    "    print(\"\\nSignificant at alpha = 0.05? No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-1-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Your Turn: Create a Different Visualization\n",
    "\n",
    "We just made a histogram. Now try creating a **swarm plot** comparing the New and Old groups.\n",
    "\n",
    "You'll need to use `sns.swarmplot()` like we did earlier. But the t-test data is in a different format (two separate columns instead of a 'Group' column), so we need to restructure it first.\n",
    "\n",
    "The code below restructures the data for you. Your job is to fill in the `sns.swarmplot()` call.\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "```python\n",
    "sns.swarmplot(data=ttest_long, x='Group', y='Score', color='purple', size=8)\n",
    "plt.title('New vs Old Treatment')\n",
    "plt.show()\n",
    "```\n",
    "Yours doesn't need to be exactly like this, but this will work :) \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-1-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, restructure the data into \"long format\" for seaborn\n",
    "# (This code is provided for you — just run it)\n",
    "ttest_long = pd.DataFrame({\n",
    "    'Group': ['New']*len(new_data) + ['Old']*len(old_data),\n",
    "    'Score': list(new_data) + list(old_data)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40711dd-0954-4d31-b488-e49f7cb9fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you check what is in ttest_long? Do that here?.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db504f1b-b85e-4d65-951c-665100332474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run swarmplot:\n",
    "\n",
    "sns.swarmplot(\n",
    "    data=...,\n",
    "    x=...,\n",
    "    y=...,\n",
    "    #anything else you want!\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paired-vs-independent",
   "metadata": {},
   "source": [
    "### Teaching Moment: Independent vs. Paired T-Tests\n",
    "\n",
    "What happens if we run the same data as a **paired** t-test? The results will differ!\n",
    "\n",
    "- **Independent t-test**: Assumes the groups are unrelated (different subjects)\n",
    "- **Paired t-test**: Assumes each observation in one group is matched to one in the other\n",
    "\n",
    "---\n",
    "\n",
    "**Important Warning:** The following is a \"what happens if we use the wrong test\" demonstration. A paired t-test requires **true subject-level pairing** (e.g., the same person measured before and after treatment). We're artificially pairing unrelated observations here to show how results change — **never do this with real data!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paired-ttest-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare independent vs paired t-tests\n",
    "# For paired t-test, we need equal sample sizes, so we use the smaller n\n",
    "\n",
    "n_min = min(len(new_data), len(old_data))\n",
    "\n",
    "# Take only the first n_min values from each group\n",
    "# WARNING: This is artificial pairing — just for demonstration!\n",
    "new_paired = new_data[:n_min]\n",
    "old_paired = old_data[:n_min]\n",
    "\n",
    "# Independent t-test (what we should use for this data)\n",
    "t_ind, p_ind = stats.ttest_ind(new_paired, old_paired)\n",
    "\n",
    "# Paired t-test (ttest_rel = \"related\" samples)\n",
    "t_paired, p_paired = stats.ttest_rel(new_paired, old_paired)\n",
    "\n",
    "print(\"COMPARISON: Independent vs. Paired T-Tests\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Using first {n_min} observations from each group\\n\")\n",
    "print(f\"Independent t-test: t = {t_ind:.3f}, p = {p_ind:.4f}\")\n",
    "print(f\"Paired t-test:      t = {t_paired:.3f}, p = {p_paired:.4f}\")\n",
    "print(\"\\nKey insight: The p-values differ!\")\n",
    "print(\"\\nWhen to use each:\")\n",
    "print(\"  - Independent: Different subjects in each group (e.g., treatment vs control)\")\n",
    "print(\"  - Paired: Same subjects measured twice (e.g., before vs after)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variance-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Checking Assumptions: Equal Variances\n",
    "\n",
    "The standard t-test assumes both groups have similar variances (spread). If they don't, we should use **Welch's t-test** instead.\n",
    "\n",
    "Let's load a second dataset where the variances are very different, then visualize and test for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variance-demo-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the second sheet from ttest_data.xlsx — this one has unequal variances\n",
    "# sheet_name=1 means the second sheet (Python counts from 0)\n",
    "\n",
    "ttest_df2 = pd.read_excel('ttest_data.xlsx', sheet_name=1)\n",
    "\n",
    "# Peek at the data\n",
    "print(\"Data Set 2 (Unequal Variances):\")\n",
    "print(ttest_df2.head())\n",
    "\n",
    "# Extract the two groups\n",
    "new_data2 = ttest_df2['New'].dropna().values\n",
    "old_data2 = ttest_df2['Old'].dropna().values\n",
    "\n",
    "print(f\"\\nNew group: mean={new_data2.mean():.1f}, SD={new_data2.std(ddof=1):.1f}\")\n",
    "print(f\"Old group: mean={old_data2.mean():.1f}, SD={old_data2.std(ddof=1):.1f}\")\n",
    "print(f\"\\nVariance ratio: {new_data2.var(ddof=1) / old_data2.var(ddof=1):.1f}x difference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the variance difference — much clearer than numbers!\n",
    "# Notice how the New group is much more spread out\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Left plot: overlapping histograms\n",
    "axes[0].hist(new_data2, bins=8, alpha=0.6, label='New (spread)', color='steelblue', edgecolor='black')\n",
    "axes[0].hist(old_data2, bins=8, alpha=0.6, label='Old (tight)', color='coral', edgecolor='black')\n",
    "axes[0].set_xlabel('Score')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Histogram: Different Variances')\n",
    "axes[0].legend()\n",
    "\n",
    "# Right plot: swarm plot\n",
    "# First restructure data for seaborn\n",
    "variance_df = pd.DataFrame({\n",
    "    'Group': ['New (spread)']*len(new_data2) + ['Old (tight)']*len(old_data2),\n",
    "    'Score': list(new_data2) + list(old_data2)\n",
    "})\n",
    "sns.swarmplot(data=variance_df, x='Group', y='Score', ax=axes[1], palette=['steelblue', 'coral'])\n",
    "axes[1].set_title('Swarm Plot: Different Variances')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"See how the New group's dots are much more spread out? That's unequal variance!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "levene-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levene's test formally checks if variances are equal\n",
    "# If p < 0.05, variances are significantly different — use Welch's t-test\n",
    "\n",
    "lev_stat, lev_p = stats.levene(new_data2, old_data2)\n",
    "\n",
    "print(\"LEVENE'S TEST FOR EQUALITY OF VARIANCES\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"Test statistic: {lev_stat:.3f}\")\n",
    "print(f\"p-value: {lev_p:.4f}\")\n",
    "\n",
    "if lev_p < 0.05:\n",
    "    print(\"\\nResult: Variances are UNEQUAL (p < 0.05)\")\n",
    "    print(\"Recommendation: Use Welch's t-test\")\n",
    "else:\n",
    "    print(\"\\nResult: Variances are similar (p >= 0.05)\")\n",
    "    print(\"Recommendation: Standard t-test is fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welch-ttest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare standard vs Welch's t-test\n",
    "# The only difference in code is equal_var=True vs equal_var=False\n",
    "\n",
    "# Standard t-test (assumes equal variances)\n",
    "t_standard, p_standard = stats.ttest_ind(new_data2, old_data2, equal_var=True)\n",
    "\n",
    "# Welch's t-test (does NOT assume equal variances)\n",
    "t_welch, p_welch = stats.ttest_ind(new_data2, old_data2, equal_var=False)\n",
    "\n",
    "print(\"T-TEST COMPARISON (Data Set 2)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nStandard t-test (equal_var=True):  t = {t_standard:.3f}, p = {p_standard:.4f}\")\n",
    "print(f\"Welch's t-test  (equal_var=False): t = {t_welch:.3f}, p = {p_welch:.4f}\")\n",
    "print(\"\\nWhen variances are unequal, Welch's t-test is more accurate!\")\n",
    "print(\"Many statisticians recommend ALWAYS using Welch's t-test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-2-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Your Turn: Run Levene's Test\n",
    "\n",
    "Run Levene's test on our original t-test data (`new_data` and `old_data`) to check if those groups have equal variances.\n",
    "\n",
    "Use `stats.levene()` just like we did above.\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "```python\n",
    "lev_stat, lev_p = stats.levene(new_data, old_data)\n",
    "print(f\"Levene's test: F = {lev_stat:.3f}, p = {lev_p:.4f}\")\n",
    "if lev_p < 0.05:\n",
    "    print(\"Variances are unequal — use Welch's t-test\")\n",
    "else:\n",
    "    print(\"Variances are similar — standard t-test is fine\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-2-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test whether new_data and old_data have equal variances\n",
    "# Use stats.levene()\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anova-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: One-Way ANOVA\n",
    "\n",
    "**Question**: Does locomotor activity differ across the 8 drug treatment groups?\n",
    "\n",
    "In JASP: ANOVA → drag Dependent Variable → drag Fixed Factors → check Post Hoc...\n",
    "\n",
    "In Python: First we need to separate our data by group, then run the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prep-anova-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data by treatment group\n",
    "# We'll store each group's data in a dictionary\n",
    "\n",
    "# A dictionary uses curly braces {} and stores key:value pairs\n",
    "groups = {}\n",
    "\n",
    "# Loop through each group name and extract that group's data\n",
    "for group_name in group_order:\n",
    "    # anova_df[anova_df['Group'] == group_name] filters to just that group\n",
    "    # ['Squares entered'] selects the column we want\n",
    "    # .values converts to a numpy array\n",
    "    groups[group_name] = anova_df[anova_df['Group'] == group_name]['Squares entered'].values\n",
    "\n",
    "# Check that it worked by printing one group\n",
    "print(f\"Control group data: {groups['Control']}\")\n",
    "print(f\"Control group n = {len(groups['Control'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anova-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running the ANOVA, let's visualize all groups\n",
    "# This swarm plot shows every data point\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Use order= to control the group order on the x-axis\n",
    "sns.swarmplot(data=anova_df, \n",
    "              x='Group', \n",
    "              y='Squares entered',\n",
    "              order=group_order,\n",
    "              color='darkblue',\n",
    "              size=5,\n",
    "              alpha=0.7)  # slight transparency\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Locomotor Activity by Treatment Group')\n",
    "plt.ylabel('Squares Entered')\n",
    "plt.xlabel('Treatment Group')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Which groups have high locomotion? Which have almost none?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oneway-anova",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the one-way ANOVA\n",
    "# stats.f_oneway() takes multiple groups as arguments\n",
    "# The * unpacks our dictionary values into separate arguments\n",
    "\n",
    "F_stat, p_value = stats.f_oneway(*groups.values())\n",
    "\n",
    "# Calculate degrees of freedom for reporting\n",
    "k = len(groups)       # number of groups\n",
    "N = len(anova_df)     # total sample size\n",
    "df_between = k - 1    # degrees of freedom between groups\n",
    "df_within = N - k     # degrees of freedom within groups\n",
    "\n",
    "# Format p-value properly (show \"p < .001\" if very small)\n",
    "if p_value < 0.001:\n",
    "    p_str = \"p < .001\"\n",
    "else:\n",
    "    p_str = f\"p = {p_value:.4f}\"\n",
    "\n",
    "print(\"ONE-WAY ANOVA: Locomotor Activity by Treatment Group\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"\\nF({df_between}, {df_within}) = {F_stat:.2f}, {p_str}\")\n",
    "print(\"\\nCompare with JASP: F(7, 102) = 82.00, p < .001\")\n",
    "\n",
    "print(\"\\nGroup means:\")\n",
    "for group_name in group_order:\n",
    "    mean = groups[group_name].mean()\n",
    "    print(f\"  {group_name:20s}: {mean:6.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posthoc-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Post-Hoc Comparisons (Tukey HSD)\n",
    "\n",
    "The ANOVA tells us groups differ, but **which** groups differ from each other?\n",
    "\n",
    "With 8 groups, we have 8×7/2 = **28 pairwise comparisons**.\n",
    "\n",
    "### Why Not Just Run 28 T-Tests?\n",
    "\n",
    "You might think: \"If I want to compare 8 groups, I'll just run all pairwise t-tests!\"\n",
    "\n",
    "**The problem:** With 28 comparisons at alpha = 0.05, you expect ~1-2 false positives by chance alone. This is called the **multiple comparisons problem**.\n",
    "\n",
    "**Solutions:**\n",
    "1. **Tukey HSD** (what we'll use) — adjusts p-values to control family-wise error rate\n",
    "2. **Bonferroni correction** — multiply each p-value by the number of tests (more conservative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tukey-hsd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tukey_hsd from scipy.stats\n",
    "from scipy.stats import tukey_hsd\n",
    "\n",
    "# Run Tukey HSD on all groups\n",
    "# We pass each group's data as a separate argument\n",
    "result = tukey_hsd(*[groups[g] for g in group_order])\n",
    "\n",
    "print(\"TUKEY HSD POST-HOC COMPARISONS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Comparison':<45} {'Mean Diff':>10} {'p-value':>10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Count significant comparisons\n",
    "n_significant = 0\n",
    "\n",
    "# Loop through all pairs of groups\n",
    "for i in range(len(group_order)):\n",
    "    for j in range(i+1, len(group_order)):\n",
    "        g1, g2 = group_order[i], group_order[j]\n",
    "        \n",
    "        # Calculate mean difference\n",
    "        mean_diff = groups[g1].mean() - groups[g2].mean()\n",
    "        \n",
    "        # Get p-value from the result matrix\n",
    "        p_val = result.pvalue[i, j]\n",
    "        \n",
    "        # Add significance stars\n",
    "        if p_val < 0.001:\n",
    "            sig_marker = \"***\"\n",
    "            n_significant += 1\n",
    "        elif p_val < 0.01:\n",
    "            sig_marker = \"**\"\n",
    "            n_significant += 1\n",
    "        elif p_val < 0.05:\n",
    "            sig_marker = \"*\"\n",
    "            n_significant += 1\n",
    "        else:\n",
    "            sig_marker = \"\"\n",
    "        \n",
    "        comparison = f\"{g1} vs {g2}\"\n",
    "        print(f\"{comparison:<45} {mean_diff:>10.2f} {p_val:>10.3f} {sig_marker}\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"Significant comparisons: {n_significant} of 28\")\n",
    "print(\"\\n*** p < .001, ** p < .01, * p < .05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "key-comparisons",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight key pharmacological findings\n",
    "# We extract specific p-values from the Tukey result matrix\n",
    "\n",
    "# Helper function to format p-values nicely\n",
    "def format_p(p):\n",
    "    if p < 0.001:\n",
    "        return \"p < .001\"\n",
    "    else:\n",
    "        return f\"p = {p:.3f}\"\n",
    "\n",
    "print(\"KEY PHARMACOLOGICAL FINDINGS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get p-values from Tukey result matrix\n",
    "# Indices match group_order: Control=0, Amph=1, Res only=2, etc.\n",
    "p_amph_ctrl = result.pvalue[0, 1]      # Control vs Amph\n",
    "p_res_ctrl = result.pvalue[0, 2]       # Control vs Res only\n",
    "p_resamph_ctrl = result.pvalue[0, 3]   # Control vs Res+Amph\n",
    "p_final_ctrl = result.pvalue[0, 7]     # Control vs Res+MT+Amph+DOPA\n",
    "\n",
    "print(\"\\n1. Amphetamine INCREASES locomotion:\")\n",
    "diff = groups['Amph'].mean() - groups['Control'].mean()\n",
    "print(f\"   Amph vs Control: +{diff:.1f} squares ({format_p(p_amph_ctrl)})\")\n",
    "\n",
    "print(\"\\n2. Reserpine ABOLISHES locomotion:\")\n",
    "diff = groups['Res only'].mean() - groups['Control'].mean()\n",
    "print(f\"   Res only vs Control: {diff:.1f} squares ({format_p(p_res_ctrl)})\")\n",
    "\n",
    "print(\"\\n3. Amphetamine PARTIALLY restores function after reserpine:\")\n",
    "print(f\"   Res+Amph mean: {groups['Res+Amph'].mean():.1f} (vs Control: {format_p(p_resamph_ctrl)})\")\n",
    "\n",
    "print(\"\\n4. MT blocks the amphetamine restoration:\")\n",
    "print(f\"   Res+MT+Amph mean: {groups['Res+MT+Amph'].mean():.1f} (essentially zero)\")\n",
    "\n",
    "print(\"\\n5. L-DOPA + Amph can restore function even with MT:\")\n",
    "print(f\"   Res+MT+Amph+DOPA mean: {groups['Res+MT+Amph+DOPA'].mean():.1f} (vs Control: {format_p(p_final_ctrl)})\")\n",
    "\n",
    "print(\"\\nThese findings demonstrate the dopamine hypothesis of locomotion!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-3-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Your Turn: Run a T-Test Between Two Groups\n",
    "\n",
    "Run an independent samples t-test comparing the `Control` group to the `Amph` group.\n",
    "\n",
    "Use `stats.ttest_ind()` with the data from the `groups` dictionary.\n",
    "\n",
    "Hint: Access Control data with `groups['Control']` and Amph data with `groups['Amph']`\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "```python\n",
    "t_stat, p_val = stats.ttest_ind(groups['Control'], groups['Amph'])\n",
    "print(f\"t = {t_stat:.3f}, p = {p_val:.4f}\")\n",
    "print(f\"Control mean: {groups['Control'].mean():.2f}\")\n",
    "print(f\"Amph mean: {groups['Amph'].mean():.2f}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-3-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Control to Amph using stats.ttest_ind()\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mfqp4br804a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Two-Way Repeated Measures ANOVA\n",
    "\n",
    "So far we've analyzed data measured at a single time point. But what if we measure the same subjects at multiple times?\n",
    "\n",
    "**The longitudinal study:** The same animals were tested again 1 week after the initial drug treatment (after the drugs wore off).\n",
    "\n",
    "**Research question:**\n",
    "- Does locomotor activity change over time?\n",
    "- Does the change depend on which drug group the animal was in?\n",
    "- Is there a Drug × Time interaction?\n",
    "\n",
    "This requires a **mixed ANOVA**:\n",
    "- **Between-subjects factor:** Drug treatment (different animals in each group)\n",
    "- **Within-subjects factor:** Time (same animals measured twice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ky37qhnaevr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeated measures ANOVA requires the pingouin library\n",
    "# This cell installs it (only needed once per session in Colab)\n",
    "!pip install pingouin -q\n",
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2v45ltsqnl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the longitudinal data\n",
    "long_df = pd.read_excel('class_data_longitudinal.xlsx')\n",
    "\n",
    "print(\"Longitudinal Data (same animals, two time points):\")\n",
    "print(long_df.head(10))\n",
    "print(f\"\\nShape: {long_df.shape}\")\n",
    "print(f\"Columns: {list(long_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forwqyabldv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean: Remove rows with missing data (marked as '.')\n",
    "# Convert 1-week column to numeric\n",
    "long_df['Week1'] = pd.to_numeric(long_df['Squares entered 1 week'], errors='coerce')\n",
    "long_df_clean = long_df.dropna(subset=['Week1'])\n",
    "print(f\"Removed {len(long_df) - len(long_df_clean)} rows with missing data\")\n",
    "\n",
    "# Add subject ID (needed for repeated measures)\n",
    "long_df_clean = long_df_clean.reset_index(drop=True)\n",
    "long_df_clean['Subject'] = range(len(long_df_clean))\n",
    "\n",
    "# Reshape to \"long format\" for pingouin\n",
    "# Each row = one observation (subject × time combination)\n",
    "df_time1 = long_df_clean[['Subject', 'Group', 'Squares entered']].copy()\n",
    "df_time1['Time'] = 'Initial'\n",
    "df_time1 = df_time1.rename(columns={'Squares entered': 'Squares'})\n",
    "\n",
    "df_time2 = long_df_clean[['Subject', 'Group', 'Week1']].copy()\n",
    "df_time2['Time'] = '1 Week'\n",
    "df_time2 = df_time2.rename(columns={'Week1': 'Squares'})\n",
    "\n",
    "rm_df = pd.concat([df_time1, df_time2], ignore_index=True)\n",
    "print(\"\\nReshaped data (long format):\")\n",
    "print(rm_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4rgym9k4qzr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize: Does the pattern differ by group over time?\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Calculate means for each Group × Time combination\n",
    "means = rm_df.groupby(['Group', 'Time'])['Squares'].mean().unstack()\n",
    "means = means.reindex(group_order)  # Use our standard group order\n",
    "\n",
    "# Plot\n",
    "means.plot(kind='bar', ax=plt.gca(), color=['steelblue', 'coral'], edgecolor='black')\n",
    "plt.title('Locomotor Activity: Initial vs 1 Week Later')\n",
    "plt.ylabel('Squares Entered (mean)')\n",
    "plt.xlabel('Treatment Group')\n",
    "plt.legend(title='Time')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice how Amph drops dramatically — the drug effect wore off!\")\n",
    "print(\"And the Res groups recovered somewhat over the week.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cra0w5prydp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the mixed ANOVA using pingouin\n",
    "# - dv: dependent variable (what we're measuring)\n",
    "# - within: within-subjects factor (Time)\n",
    "# - between: between-subjects factor (Group)\n",
    "# - subject: identifies each subject\n",
    "\n",
    "aov = pg.mixed_anova(data=rm_df,\n",
    "                     dv='Squares',\n",
    "                     within='Time',\n",
    "                     between='Group',\n",
    "                     subject='Subject')\n",
    "\n",
    "print(\"TWO-WAY MIXED ANOVA RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(aov.round(4).to_string())\n",
    "\n",
    "print(\"\\n--- Interpretation ---\")\n",
    "for idx, row in aov.iterrows():\n",
    "    effect = row['Source']\n",
    "    f_val = row['F']\n",
    "    p_val = row['p-unc']\n",
    "    p_str = \"p < .001\" if p_val < 0.001 else f\"p = {p_val:.4f}\"\n",
    "    sig = \"**SIGNIFICANT**\" if p_val < 0.05 else \"not significant\"\n",
    "    print(f\"{effect}: F = {f_val:.2f}, {p_str} — {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9xk7eqvyipj",
   "metadata": {},
   "source": [
    "### What do the results mean?\n",
    "\n",
    "- **Group effect:** Do drug groups differ overall (averaging across time)?\n",
    "- **Time effect:** Does locomotion change from initial to 1 week (averaging across groups)?\n",
    "- **Group × Time interaction:** Does the TIME effect depend on which GROUP you're in?\n",
    "\n",
    "The **interaction** is often the most interesting! It tells us whether drug effects persist or fade over time differently for different treatments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advantage-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Things Python Can Do That JASP Can't\n",
    "\n",
    "### Advantage 1: Automation\n",
    "\n",
    "What if you needed to run pairwise comparisons for multiple outcome measures? In JASP, you'd click through menus dozens of times. In Python, it's a loop.\n",
    "\n",
    "**Warning:** Running many t-tests without correction inflates your false positive rate! This is just to demonstrate automation — always use Tukey HSD or Bonferroni correction for real analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automation-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all 28 pairwise t-tests in a loop\n",
    "# This demonstrates automation — NOT recommended without correction!\n",
    "\n",
    "print(\"AUTOMATED PAIRWISE T-TESTS (28 comparisons)\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Store results in a list\n",
    "results_list = []\n",
    "\n",
    "# Nested loops go through all pairs\n",
    "for i in range(len(group_order)):\n",
    "    for j in range(i+1, len(group_order)):  # j > i avoids duplicates\n",
    "        g1, g2 = group_order[i], group_order[j]\n",
    "        \n",
    "        # Run t-test\n",
    "        t, p = stats.ttest_ind(groups[g1], groups[g2])\n",
    "        \n",
    "        # Store in our results list\n",
    "        results_list.append({\n",
    "            'Group 1': g1,\n",
    "            'Group 2': g2,\n",
    "            't': t,\n",
    "            'p': p,\n",
    "            'significant': p < 0.05\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame for easy viewing\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "print(f\"\\nRan {len(results_df)} t-tests in a loop.\")\n",
    "print(f\"Significant results (uncorrected): {results_df['significant'].sum()}\")\n",
    "\n",
    "# Apply Bonferroni correction\n",
    "# Multiply each p-value by the number of tests\n",
    "results_df['p_bonferroni'] = (results_df['p'] * len(results_df)).clip(upper=1.0)\n",
    "results_df['sig_corrected'] = results_df['p_bonferroni'] < 0.05\n",
    "\n",
    "print(f\"Significant after Bonferroni correction: {results_df['sig_corrected'].sum()}\")\n",
    "\n",
    "print(\"\\nIn JASP, you'd click through 28 separate comparisons.\")\n",
    "print(\"In Python, 10 lines of code.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "### Advantage 2: Custom Visualizations\n",
    "\n",
    "JASP gives you canned plots. Python gives you full control over every aspect of your figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bar-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a publication-quality bar plot with error bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Calculate means and standard errors for each group\n",
    "means = [groups[g].mean() for g in group_order]\n",
    "sems = [groups[g].std() / np.sqrt(len(groups[g])) for g in group_order]\n",
    "\n",
    "# Color code by drug effect\n",
    "# Try changing these colors! Options: 'red', 'blue', 'green', 'orange', 'purple', etc.\n",
    "colors = ['green',      # Control\n",
    "          'red',        # Amph (stimulant effect)\n",
    "          'royalblue',  # Res only (depleted)\n",
    "          'orange',     # Res+Amph (partial restoration)\n",
    "          'royalblue',  # Res+MT\n",
    "          'royalblue',  # Res+MT+Amph\n",
    "          'royalblue',  # Res+MT+DOPA\n",
    "          'orange']     # Res+MT+Amph+DOPA (restoration)\n",
    "\n",
    "# Create the bar plot\n",
    "# yerr adds error bars, capsize sets the width of the error bar caps\n",
    "bars = ax.bar(range(len(group_order)), means, yerr=sems, \n",
    "              color=colors, edgecolor='black', capsize=4, alpha=0.8)\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xticks(range(len(group_order)))\n",
    "ax.set_xticklabels(group_order, rotation=45, ha='right', fontsize=10)\n",
    "ax.set_ylabel('Squares Entered (mean +/- SEM)', fontsize=12)\n",
    "ax.set_xlabel('Treatment Group', fontsize=12)\n",
    "\n",
    "# Add title with our computed statistics\n",
    "if p_value < 0.001:\n",
    "    title_p = \"p < .001\"\n",
    "else:\n",
    "    title_p = f\"p = {p_value:.3f}\"\n",
    "ax.set_title(f'Locomotor Activity by Treatment\\nF({df_between}, {df_within}) = {F_stat:.2f}, {title_p}', fontsize=14)\n",
    "\n",
    "# Add a horizontal reference line at Control mean\n",
    "ax.axhline(y=groups['Control'].mean(), color='gray', linestyle='--', alpha=0.5, label='Control baseline')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Color key: Green=Control, Red=Stimulant, Blue=Depleted, Orange=Restored\")\n",
    "print(\"\\nTry changing the colors list above and re-running!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bootstrap-header",
   "metadata": {},
   "source": [
    "### Advantage 3: Bootstrap Confidence Intervals\n",
    "\n",
    "This isn't even an option in JASP's menus. In Python, it's straightforward.\n",
    "\n",
    "### Why Bootstrap?\n",
    "\n",
    "Traditional statistics assume your data follows a specific distribution (usually normal). But what if it doesn't? Or what if you have a small sample?\n",
    "\n",
    "**Bootstrapping** lets you estimate uncertainty without those assumptions:\n",
    "1. Resample your data (with replacement) thousands of times\n",
    "2. Calculate your statistic each time\n",
    "3. The spread of those results IS your confidence interval\n",
    "\n",
    "This is especially useful when:\n",
    "- Sample sizes are small\n",
    "- Data is skewed or has outliers\n",
    "- You want to verify your results aren't dependent on distributional assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bootstrap-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap confidence interval for Amph vs Control difference\n",
    "\n",
    "amph = groups['Amph']\n",
    "control = groups['Control']\n",
    "\n",
    "# Number of bootstrap samples — more = more precise but slower\n",
    "n_bootstrap = 10000\n",
    "\n",
    "# Store bootstrapped differences\n",
    "boot_diffs = []\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Bootstrap loop\n",
    "for _ in range(n_bootstrap):\n",
    "    # Resample WITH replacement (some values will be picked multiple times)\n",
    "    boot_amph = np.random.choice(amph, size=len(amph), replace=True)\n",
    "    boot_ctrl = np.random.choice(control, size=len(control), replace=True)\n",
    "    \n",
    "    # Calculate mean difference for this resample\n",
    "    boot_diffs.append(boot_amph.mean() - boot_ctrl.mean())\n",
    "\n",
    "boot_diffs = np.array(boot_diffs)\n",
    "\n",
    "# Calculate confidence interval using percentiles\n",
    "ci_lower = np.percentile(boot_diffs, 2.5)\n",
    "ci_upper = np.percentile(boot_diffs, 97.5)\n",
    "\n",
    "print(\"BOOTSTRAP ANALYSIS (10,000 resamples)\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"\\nAmphetamine vs Control difference:\")\n",
    "print(f\"  Observed difference: {amph.mean() - control.mean():.1f} squares\")\n",
    "print(f\"  Bootstrap mean:      {np.mean(boot_diffs):.1f} squares\")\n",
    "print(f\"  95% CI: [{ci_lower:.1f}, {ci_upper:.1f}]\")\n",
    "print(f\"\\nProportion where Amph > Control: {(boot_diffs > 0).mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bootstrap-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the bootstrap distribution\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Histogram of bootstrap differences\n",
    "plt.hist(boot_diffs, bins=50, edgecolor='black', alpha=0.7, color='indianred')\n",
    "\n",
    "# Add vertical lines for reference\n",
    "plt.axvline(0, color='black', linewidth=2, linestyle='--', label='No difference')\n",
    "plt.axvline(ci_lower, color='navy', linewidth=2, linestyle=':', label='95% CI')\n",
    "plt.axvline(ci_upper, color='navy', linewidth=2, linestyle=':')\n",
    "\n",
    "plt.xlabel('Amphetamine - Control (squares entered)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Bootstrap Distribution of Mean Difference')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The entire distribution is above zero — strong evidence that Amph > Control!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reproducibility-header",
   "metadata": {},
   "source": [
    "### Advantage 4: Reproducibility\n",
    "\n",
    "If someone asks *\"How did you get that result?\"*, you can hand them this notebook. Every step is documented, every analysis is re-runnable.\n",
    "\n",
    "In JASP, you'd have to write out: *\"I clicked ANOVA, then dragged Squares entered into the dependent variable box, then I dragged Group into the grouping variable, then I checked the Tukey option under Post Hoc...\"*\n",
    "\n",
    "In Python, the code **is** the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "error-box",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Errors and What They Mean\n",
    "\n",
    "When you see an error, don't panic! Here's what common errors mean:\n",
    "\n",
    "| Error | What it means | How to fix |\n",
    "|-------|---------------|------------|\n",
    "| `FileNotFoundError` | Python can't find the file | Check filename spelling, make sure file is in the same folder as the notebook |\n",
    "| `KeyError: 'column_name'` | That column doesn't exist in your data | Check spelling with `df.columns` to see all column names |\n",
    "| `ValueError: could not convert string to float` | There's text in a column that should be numbers | Check for header rows or non-numeric data with `df.head()` |\n",
    "| `NameError: name 'x' is not defined` | You're using a variable before creating it | Make sure you ran the cell that creates that variable first |\n",
    "| `IndentationError` | Python code isn't lined up correctly | Check that spaces/tabs are consistent |\n",
    "\n",
    "**Pro tip:** Read error messages from the bottom up — the last line usually tells you what went wrong!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rm-anova-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonus: More Repeated Measures Options\n",
    "\n",
    "In Part 5, we used `pingouin` for the mixed ANOVA. The library also supports:\n",
    "\n",
    "**Within-subjects only ANOVA** (all factors are repeated measures):\n",
    "```python\n",
    "pg.rm_anova(data=df, dv='Score', within='Time', subject='Subject')\n",
    "```\n",
    "\n",
    "**Multiple within-subjects factors**:\n",
    "```python\n",
    "pg.rm_anova(data=df, dv='Score', within=['Time', 'Condition'], subject='Subject')\n",
    "```\n",
    "\n",
    "See the full documentation at: [pingouin-stats.org](https://pingouin-stats.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recap",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checkpoint: JASP vs Python\n",
    "\n",
    "You just replicated **every test** from the JASP lab in Python. Let's count the lines of code:\n",
    "\n",
    "| Test | Python Code | JASP |\n",
    "|------|-------------|------|\n",
    "| Independent t-test | `stats.ttest_ind(a, b)` — **1 line** | 4-5 clicks, drag variables |\n",
    "| Paired t-test | `stats.ttest_rel(a, b)` — **1 line** | Reshape data, 4-5 clicks |\n",
    "| Welch's t-test | `stats.ttest_ind(a, b, equal_var=False)` — **1 line** | Buried in options menu |\n",
    "| Levene's test | `stats.levene(a, b)` — **1 line** | Separate analysis |\n",
    "| One-way ANOVA | `stats.f_oneway(g1, g2, ...)` — **1 line** | 3-4 clicks, check boxes |\n",
    "| Tukey HSD | `tukey_hsd(g1, g2, ...)` — **1 line** | Check post-hoc options |\n",
    "| 28 pairwise tests | Loop: 10 lines total | Click 28x through menus |\n",
    "\n",
    "The tests are equally simple. **But Python can do things JASP cannot.** We demonstrated:\n",
    "- Automation (loop through all comparisons)\n",
    "- Custom publication-quality visualizations\n",
    "- Bootstrap confidence intervals\n",
    "- Complete reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: The Python Cheat Sheet\n",
    "\n",
    "| What you want to do | Python code |\n",
    "|---|---|\n",
    "| Load Excel data | `df = pd.read_excel('file.xlsx')` |\n",
    "| Load CSV data | `df = pd.read_csv('file.csv')` |\n",
    "| View first rows | `df.head()` |\n",
    "| Check data structure | `df.info()` |\n",
    "| Check for missing values | `df.isna().sum()` |\n",
    "| Group means | `df.groupby('Group')['DV'].mean()` |\n",
    "| Descriptive stats | `df.groupby('Group')['DV'].agg(['count', 'mean', 'std'])` |\n",
    "| Independent t-test | `stats.ttest_ind(group1, group2)` |\n",
    "| Welch's t-test | `stats.ttest_ind(group1, group2, equal_var=False)` |\n",
    "| Paired t-test | `stats.ttest_rel(pre, post)` |\n",
    "| Levene's test | `stats.levene(group1, group2)` |\n",
    "| One-way ANOVA | `stats.f_oneway(g1, g2, g3, ...)` |\n",
    "| Tukey HSD | `tukey_hsd(g1, g2, g3, ...)` |\n",
    "| Mixed ANOVA (repeated measures) | `pg.mixed_anova(data=df, dv='Score', within='Time', between='Group', subject='Subject')` |\n",
    "| Histogram | `plt.hist(x, bins=10, color='blue')` |\n",
    "| Swarm plot | `sns.swarmplot(data=df, x='Group', y='Value')` |\n",
    "| Bar plot | `plt.bar(x, heights, yerr=errors)` |\n",
    "\n",
    "**That's it.** With these functions, you can do everything JASP does — and much more.\n",
    "\n",
    "You don't have to memorize them. There is no test. The more you use them, the more you will remember.\n",
    "\n",
    "**Remember:** The skills you learned today transfer directly to machine learning, neuroimaging, bioinformatics, and countless other fields!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a85242-9331-4ef9-9128-32e25a1bb6d8",
   "metadata": {},
   "source": [
    "For more, check out this great talk on why data science (and statistics in general) is better when done with code instead of with a GUI:\n",
    "\n",
    "\n",
    "https://www.youtube.com/watch?v=cpbtcsGE0OA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c154d5-f9ff-4816-a741-940d9696fbb5",
   "metadata": {},
   "source": [
    "It's a long video, but you can find a summary of the key points here \n",
    "\n",
    "https://asterisk.dynevor.org/you-cant-do-data-science-in-a-gui.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1e0c5a-0a44-4d45-99b1-48ce0793d343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
